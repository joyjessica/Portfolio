[
  {
    "objectID": "technical-details/progress-log.html",
    "href": "technical-details/progress-log.html",
    "title": "Progress log",
    "section": "",
    "text": "M: 11-04-2024\n\nbrainstorming topics with GPT\n\nT: 11-14-2024\n\nstarted literature review\nstarted collecting data from Census API and NYC InfoHub\n\nM: 11-25-2024\n\nwrite up data collection and cleaning section\n\nM: 11-26-2024\n\nwork on EDA and write ups\nbegin unsupervised learning\n\nM: 12-8-2024\n\nadd random forest and boosting algorithms to regression\nwork on binary classification: random forest and gradient boosting\n\nT: 12-12-2024\n\nadd Lasso regression to regression algorithms\nwrite up supervised learning methods and conclusions\n\nF: 12-13-2024\n\nwork on unsupervised learning methods and write conclusions\nfinish machine learning methods and write conclusions\n\nS: 12-14-2024\n\nwork on final report\n\nS: 12-15-2024\n\nproofread and push to site"
  },
  {
    "objectID": "report/report.html",
    "href": "report/report.html",
    "title": "Final Report",
    "section": "",
    "text": "High school dropout rates have a profound impact on students, families, and communities. To bring these numbers down, it’s essential to first understand what’s driving them. This study takes a closer look at how the quality of schools and the socioeconomic challenges students face influence high school outcomes in New York City. By diving into these factors, the goal is to uncover ways to help students succeed.\n\n\n\nHow does a school’s environment contribute to better student outcomes?\nWhat are the most significant predictors of student absenteeism, dropout rates and college persistence?\nWhat are the interactions between chronic absenteeism, dropout rates, and college persistence?\nHow does socioeconomic status impact student absenteeism, dropout rates and college persistence?\nHow can early academic indicators be used to identify schools at risk of high dropout or not persisting in college?\n\n\n\n\n\nCollect and clean data, creating a comprehensive dataset of NYC high schools\nPerform exploratory data analysis to uncover trends in the data\nPerform unsupervised learning and supervised learning to find real relationships between the features and targets: chronic absenteeism, dropout rates, and college persistence\nSummarize findings into actionable insights\n\n\n\n\nThis dataset contains 500 New York City public high schools. We can begin by taking a look at dropout rates across New York City Boroughs, revealing areas of needed intervention.\n\n\n\n\n\nFigure 1: Boroughs of New York City\n\n\n\n\n\n\n\nFigure 2: Boxplot of dropout rates by NYC Borough\n\n\n\n\nIt is evident that the highest median drop out rate is in the Bronx, followed by Brooklyn. Although there are some high outliers in Queens. This highlights boroughs where intervention is necessary. To take a closer look, we can look at drop out rates by specific NYC school districts.\n\n\n\n\nFigure 3: Boxplot of dropout rates by NYC DOE Districts\n\n\n\nThis plot clearly shows the highest drop out rate to be in district 12, which is located in the Bronx. Next is district 8 which is also located in the Bronx. This plot makes it easier to pinpoint school districts that need to be targeted.\nNext, we will examine specific socioeconomic and school features that are hypothesized to impact our target outcomes.\n\n\n\n\n\nFigure 4: Scatter plot of median household income by dropout rate\n\n\n\n\n\n\n\nFigure 5: Scatter plot of chronic absenteeism vs school environment\n\n\n\n\nUsing statistical testing, it was concluded that there is a statistically significant difference in mean median household income between high schools with high dropout rates and those with low dropout rates. This suggests that students from higher income households, likely with parents who have degrees and employment, are less likely to drop out themselves. This emphasizes the importance of addressing economic disparities to improve these rates.\nSupportive Environment score comes from the NYC Quality report and is defined as, “how well the school establishes a culture where students feel safe, challenged to grow, and supported to meet high expectations”1. There is a statistically significant difference in the mean supportive environment score for a school with high and low rates of chronic absenteeism. This is important because it shows that when students feel good about the school environment, and feel a sense of value and community, they are less likely to skip class or be absent.\n\n\n\n\nFigure 6: Scatter plot of college persistence vs average grade 8 proficiency\n\n\n\nFigure 6 highlights a strong relationship between college persistence and average grade 8 proficiency, emphasizing the critical need for early intervention. Students who perform well in 8th grade are more likely to succeed in college and persist through their studies. This highlights the importance of addressing academic gaps during middle school, before they affect long-term outcomes in order to set students up for success.\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: PCA results\n\n\n\n\n\n\n\nFigure 8: t-SNE results\n\n\n\n\nPCA was applied to the socioeconomic factors, revealing a pattern in Figure 7 where schools with higher dropout rates are positioned towards the top of the plot, while those with lower dropout rates are found towards the bottom. This illustrates the significant impact of socioeconomic factors on dropout rates.\nT-SNE was able to uncover certain patterns in the data and differentiate schools with varying levels of college persistence in Figure 8. While there is some overlap, the gradient becomes lighter as it moves to the right. This emphasizes the model’s ability to distinguish schools based on their college persistence levels\n\n\n\n\n\n\n\nFigure 9: Agglomerative clustering results\n\n\n\n\n\n\nFigure 10: Boxplot of agglomerative clusters vs targets\n\n\nAgglomerative Clustering worked best for this data, and was able to find patterns in the data. Looking at the boxplot in Figure 9, it is clear that Cluster 1 contains schools with the best student outcomes: low chronic absenteeism, low dropout rates, and high college persistence. This indicates that the algorithm successfully identified meaningful patterns in the data, emphasizing the role these features play in evaluating high school outcomes.\n\n\n\n\n\n\nTarget: Chronic Absenteeism\n\n\n\nFigure 11: LASSO regression feature importance\n\n\nThe LASSO regression gave the features most important to our target, chronic absenteeism. Supportive Environment score emerging as the most important variable in our model. This score reflects how well a school fosters a supportive, challenging environment for students1. The next key feature was Average Grade 8 Proficiency. This metric emphasizes how important it is for children to be on the right track from a young age. The third important factor was Rigorous Instruction score, which measures how engaging and effective the curriculum is in promoting critical-thinking skills1. Additionally, significant socioeconomic factors contributing to chronic absenteeism included Percent English Language Learners and Percent in Temporary Housing.\n\n\n\nTarget: Classifying Schools with High vs. Low Dropout Risk\n\n\n\nMetric\nClass 0\nClass 1\nAccuracy\n\n\n\n\nPrecision\n0.97\n0.69\n\n\n\nRecall\n0.89\n0.91\n\n\n\nF1-Score\n0.93\n0.78\n0.89\n\n\n\nBased on the recall score, the gradient boosting model successfully identified high-risk dropout schools 91% of the time. These results suggest that the model can accurately predict schools at high risk of dropout, enabling targeted interventions to address key factors contributing to dropout risk.\n\n\n\nFigure 12: Gradient boosting classification feature importancegb\n\n\nThe top 15 important features highlight several key factors, with college persistence ranking the highest. This suggests that schools struggling with dropout risk may also have issues with retaining students after their first year of college. Other significant features include the percentage of students in temporary housing and the percentage of overage/undercredited students (students with very few credits), which indicates a strong relationship between socioeconomic challenges and dropout rates.\n\n\n\nTarget: Classifying Schools with High vs. Medium vs. Low College Persistence\n\n\n\nMetric\nHigh\nLow\nMedium\nAccuracy\n\n\n\n\nPrecision\n0.60\n0.67\n0.92\n\n\n\nRecall\n0.86\n0.91\n0.72\n\n\n\nF1-Score\n0.71\n0.77\n0.81\n0.78\n\n\n\nExamining the recall scores, this gradient boosting multiclass classification model successfully predicts 86% of schools with high college persistence, 72% of schools with medium college persistence, and 91% of schools with low college persistence. While there is room for improvement in predicting the medium category, the model’s ability to accurately identify schools with low college persistence is particularly significant, as this is where intervention is most needed.\n\n\n\nFigure 13: Gradient boosting classification feature importancegb\n\n\nLooking at the feature importance, similar to what was seen in the regression model for chronic absenteeism, Average Grade 8 Proficiency is the most important driver of college persistence. It is interesting that this metric continues to have predictive power at the college level. Additionally, both dropout rate and the percentage of chronically absent students are significant features in this model, highlighting the interconnectedness of these metrics within schools that must be addressed.\n\n\n\n\nGrade 8 Proficiency is a crucial indicator of future success, highlighting the importance of early intervention to address academic challenges before they escalate\nSupportive and Trusting Environments contribute to better student outcomes, emphasizing the need for schools to create cultures where students feel safe, supported, and motivated\nEconomic Disadvantage plays a significant role in long-term outcomes such as college persistence, with students from lower-income backgrounds facing more barriers to succes\nThe Connection: Chronic absenteeism, dropout rates, and college persistence are closely linked. Addressing absenteeism early is key to preventing dropout and ensuring students stay on track for college success.\n\nBy identifying and understanding the key drivers, such as school environment and socioeconomic factors, targeted strategies can be developed to support students more effectively. Empowering schools to create safe, supportive, and inclusive environments, while addressing broader economic challenges, is essential to ensure that every student has the opportunity to succeed academically and beyond."
  },
  {
    "objectID": "report/report.html#breaking-the-cycle-key-findings-and-takeaways",
    "href": "report/report.html#breaking-the-cycle-key-findings-and-takeaways",
    "title": "Final Report",
    "section": "",
    "text": "High school dropout rates have a profound impact on students, families, and communities. To bring these numbers down, it’s essential to first understand what’s driving them. This study takes a closer look at how the quality of schools and the socioeconomic challenges students face influence high school outcomes in New York City. By diving into these factors, the goal is to uncover ways to help students succeed.\n\n\n\nHow does a school’s environment contribute to better student outcomes?\nWhat are the most significant predictors of student absenteeism, dropout rates and college persistence?\nWhat are the interactions between chronic absenteeism, dropout rates, and college persistence?\nHow does socioeconomic status impact student absenteeism, dropout rates and college persistence?\nHow can early academic indicators be used to identify schools at risk of high dropout or not persisting in college?\n\n\n\n\n\nCollect and clean data, creating a comprehensive dataset of NYC high schools\nPerform exploratory data analysis to uncover trends in the data\nPerform unsupervised learning and supervised learning to find real relationships between the features and targets: chronic absenteeism, dropout rates, and college persistence\nSummarize findings into actionable insights\n\n\n\n\nThis dataset contains 500 New York City public high schools. We can begin by taking a look at dropout rates across New York City Boroughs, revealing areas of needed intervention.\n\n\n\n\n\nFigure 1: Boroughs of New York City\n\n\n\n\n\n\n\nFigure 2: Boxplot of dropout rates by NYC Borough\n\n\n\n\nIt is evident that the highest median drop out rate is in the Bronx, followed by Brooklyn. Although there are some high outliers in Queens. This highlights boroughs where intervention is necessary. To take a closer look, we can look at drop out rates by specific NYC school districts.\n\n\n\n\nFigure 3: Boxplot of dropout rates by NYC DOE Districts\n\n\n\nThis plot clearly shows the highest drop out rate to be in district 12, which is located in the Bronx. Next is district 8 which is also located in the Bronx. This plot makes it easier to pinpoint school districts that need to be targeted.\nNext, we will examine specific socioeconomic and school features that are hypothesized to impact our target outcomes.\n\n\n\n\n\nFigure 4: Scatter plot of median household income by dropout rate\n\n\n\n\n\n\n\nFigure 5: Scatter plot of chronic absenteeism vs school environment\n\n\n\n\nUsing statistical testing, it was concluded that there is a statistically significant difference in mean median household income between high schools with high dropout rates and those with low dropout rates. This suggests that students from higher income households, likely with parents who have degrees and employment, are less likely to drop out themselves. This emphasizes the importance of addressing economic disparities to improve these rates.\nSupportive Environment score comes from the NYC Quality report and is defined as, “how well the school establishes a culture where students feel safe, challenged to grow, and supported to meet high expectations”1. There is a statistically significant difference in the mean supportive environment score for a school with high and low rates of chronic absenteeism. This is important because it shows that when students feel good about the school environment, and feel a sense of value and community, they are less likely to skip class or be absent.\n\n\n\n\nFigure 6: Scatter plot of college persistence vs average grade 8 proficiency\n\n\n\nFigure 6 highlights a strong relationship between college persistence and average grade 8 proficiency, emphasizing the critical need for early intervention. Students who perform well in 8th grade are more likely to succeed in college and persist through their studies. This highlights the importance of addressing academic gaps during middle school, before they affect long-term outcomes in order to set students up for success.\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: PCA results\n\n\n\n\n\n\n\nFigure 8: t-SNE results\n\n\n\n\nPCA was applied to the socioeconomic factors, revealing a pattern in Figure 7 where schools with higher dropout rates are positioned towards the top of the plot, while those with lower dropout rates are found towards the bottom. This illustrates the significant impact of socioeconomic factors on dropout rates.\nT-SNE was able to uncover certain patterns in the data and differentiate schools with varying levels of college persistence in Figure 8. While there is some overlap, the gradient becomes lighter as it moves to the right. This emphasizes the model’s ability to distinguish schools based on their college persistence levels\n\n\n\n\n\n\n\nFigure 9: Agglomerative clustering results\n\n\n\n\n\n\nFigure 10: Boxplot of agglomerative clusters vs targets\n\n\nAgglomerative Clustering worked best for this data, and was able to find patterns in the data. Looking at the boxplot in Figure 9, it is clear that Cluster 1 contains schools with the best student outcomes: low chronic absenteeism, low dropout rates, and high college persistence. This indicates that the algorithm successfully identified meaningful patterns in the data, emphasizing the role these features play in evaluating high school outcomes.\n\n\n\n\n\n\nTarget: Chronic Absenteeism\n\n\n\nFigure 11: LASSO regression feature importance\n\n\nThe LASSO regression gave the features most important to our target, chronic absenteeism. Supportive Environment score emerging as the most important variable in our model. This score reflects how well a school fosters a supportive, challenging environment for students1. The next key feature was Average Grade 8 Proficiency. This metric emphasizes how important it is for children to be on the right track from a young age. The third important factor was Rigorous Instruction score, which measures how engaging and effective the curriculum is in promoting critical-thinking skills1. Additionally, significant socioeconomic factors contributing to chronic absenteeism included Percent English Language Learners and Percent in Temporary Housing.\n\n\n\nTarget: Classifying Schools with High vs. Low Dropout Risk\n\n\n\nMetric\nClass 0\nClass 1\nAccuracy\n\n\n\n\nPrecision\n0.97\n0.69\n\n\n\nRecall\n0.89\n0.91\n\n\n\nF1-Score\n0.93\n0.78\n0.89\n\n\n\nBased on the recall score, the gradient boosting model successfully identified high-risk dropout schools 91% of the time. These results suggest that the model can accurately predict schools at high risk of dropout, enabling targeted interventions to address key factors contributing to dropout risk.\n\n\n\nFigure 12: Gradient boosting classification feature importancegb\n\n\nThe top 15 important features highlight several key factors, with college persistence ranking the highest. This suggests that schools struggling with dropout risk may also have issues with retaining students after their first year of college. Other significant features include the percentage of students in temporary housing and the percentage of overage/undercredited students (students with very few credits), which indicates a strong relationship between socioeconomic challenges and dropout rates.\n\n\n\nTarget: Classifying Schools with High vs. Medium vs. Low College Persistence\n\n\n\nMetric\nHigh\nLow\nMedium\nAccuracy\n\n\n\n\nPrecision\n0.60\n0.67\n0.92\n\n\n\nRecall\n0.86\n0.91\n0.72\n\n\n\nF1-Score\n0.71\n0.77\n0.81\n0.78\n\n\n\nExamining the recall scores, this gradient boosting multiclass classification model successfully predicts 86% of schools with high college persistence, 72% of schools with medium college persistence, and 91% of schools with low college persistence. While there is room for improvement in predicting the medium category, the model’s ability to accurately identify schools with low college persistence is particularly significant, as this is where intervention is most needed.\n\n\n\nFigure 13: Gradient boosting classification feature importancegb\n\n\nLooking at the feature importance, similar to what was seen in the regression model for chronic absenteeism, Average Grade 8 Proficiency is the most important driver of college persistence. It is interesting that this metric continues to have predictive power at the college level. Additionally, both dropout rate and the percentage of chronically absent students are significant features in this model, highlighting the interconnectedness of these metrics within schools that must be addressed.\n\n\n\n\nGrade 8 Proficiency is a crucial indicator of future success, highlighting the importance of early intervention to address academic challenges before they escalate\nSupportive and Trusting Environments contribute to better student outcomes, emphasizing the need for schools to create cultures where students feel safe, supported, and motivated\nEconomic Disadvantage plays a significant role in long-term outcomes such as college persistence, with students from lower-income backgrounds facing more barriers to succes\nThe Connection: Chronic absenteeism, dropout rates, and college persistence are closely linked. Addressing absenteeism early is key to preventing dropout and ensuring students stay on track for college success.\n\nBy identifying and understanding the key drivers, such as school environment and socioeconomic factors, targeted strategies can be developed to support students more effectively. Empowering schools to create safe, supportive, and inclusive environments, while addressing broader economic challenges, is essential to ensure that every student has the opportunity to succeed academically and beyond."
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About Me",
    "section": "",
    "text": "Jessica Joy is a full-time student in the Data Science and Analytics program at Georgetown University. She earned her Bachelor of Science in Financial Economics from Binghamton University in 2020. Before joining the DSAN program, she worked as a senior data analyst at EssenceMediacom, a marketing agency in New York City, where she contributed to various projects, including Marketing Mix Models and ad optimizations. She is excited to further develop her data skills and apply them to other industries."
  },
  {
    "objectID": "aboutme.html#skills",
    "href": "aboutme.html#skills",
    "title": "About Me",
    "section": "Skills",
    "text": "Skills"
  },
  {
    "objectID": "aboutme.html#education",
    "href": "aboutme.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\n\nGeorgetown University\nMS Data Science and Analytics (Expected May 2026)\nCurrent relevant coursework:\n\nData Science and Analytics\n\nProbabilistic Modeling and Statistical Computing\n\nComputational Linguistics with Advanced Python\n\nBinghamton University\nBS Financial Economics (May 2020)\nMajor GPA: 3.78/4.00\nInvolvement/Activities:\n\nStudent-Athlete Success Center, Microeconomics Theory and Macroeconomics Tutor\n\nAlpha Epsilon Phi, Treasury Committee\n\nHelping Hand Project, Founding Member"
  },
  {
    "objectID": "aboutme.html#professional-experience",
    "href": "aboutme.html#professional-experience",
    "title": "About Me",
    "section": "Professional Experience",
    "text": "Professional Experience\nEssenceMediacom: New York, NY\nSenior Analyst, Data Science and Modeling (June 2021 – August 2024)\n\nDeveloped end-to-end Marketing Mix Models (MMM) for major clients, improving data processing and efficiency of 10M+ rows of creative data using Python, R, and SQL. Applied multiple linear regression modeling and validation to create final deliverables of actionable insights, resulting in increased marketing ROI.\n\nConstructed a budget allocation tool using marketing mix model outputs, optimizing media mix strategies and driving up to a 30% increase in incremental revenue growth for clients.\n\nProvided strategic consultation to Dell, leveraging vision AI data and advanced machine learning algorithms (Linear/Logistic Regression, K-Means Clustering, PCA) to analyze 200+ variables, potentially increasing KPIs by 130% through creative attribute optimization.\n\nStrengthened new business pitches by building a database of 70+ marketing metrics for the “Remarkability Index,” effectively evaluating investments and securing new clients."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html",
    "href": "technical-details/supervised-learning/main.html",
    "title": "Supervised Learning",
    "section": "",
    "text": "In this section, the goal is to build machine learning models to investigate the drivers of our target variables: chronic absenteeism, dropout risk, and college persistence. I will create three different models: a regression, a binary classification, and a multivariate classification. For each, I will test various algorithms and identify the one that performs best.\nI developed several functions to streamline the modeling process. These functions handle preprocessing, training, tuning, scoring the validation set, and scoring the test set.\nCode\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, confusion_matrix, classification_report\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn import datasets, linear_model\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import Lasso, LassoCV\nfrom imblearn.over_sampling import SMOTE\n\nimport statsmodels.api as sm\nfrom scipy import stats\nCode\ndf = pd.read_csv('../../data/processed-data/processed_df.csv', index_col=None)\ndf_regression = pd.read_csv('../../data/processed-data/df_subset_regression.csv', index_col=None)\nCode\n# Drop categorical and identifier columns we dont need\ndf.drop(columns=['DBN', 'School Name', 'District', 'zip code', 'Borough'], inplace=True)\n#drop columns that cause perfect multicollinearity\ndf_clean = df.drop(['Median Household Income',\"Percent Bachelor's Degree or Higher (25+)\",'Percent No High School (25+)','Student Percent - Other', 'Percent Female','Percent College Ready based on SAT Math'], axis=1)\nCode\ndef preprocessing(df, target_column, test_size=0.2):\n       \"\"\"Splits the data into training and test sets.\"\"\"\n       X = df.drop(columns=[target_column])\n       y = df[target_column]\n       #split into training, validation, test set\n       X_train1, X_test, y_train1, y_test = train_test_split(X, y, test_size=test_size, shuffle=True)\n       X_train, X_val, y_train, y_val = train_test_split(X_train1, y_train1, test_size=test_size, shuffle=True)\n       #standardize\n       scaler = StandardScaler()\n       X_train = scaler.fit_transform(X_train)\n       X_val = scaler.transform(X_val)\n       X_test = scaler.transform(X_test)\n       return X, y, X_train, X_val, X_test, y_train, y_val, y_test\nCode\ndef train(X_train, y_train, learning_task_type, model_type, **kwargs):\n    \"\"\"Trains a machine learning model.\"\"\"\n    if learning_task_type == 'regression':\n        if model_type == 'random_forest':\n            model = RandomForestRegressor(**kwargs)\n        elif model_type == 'lasso_regression':\n            model = Lasso(**kwargs)\n        elif model_type == 'gradient_boosting':\n            model = GradientBoostingRegressor(**kwargs)\n        else:\n            raise ValueError(\"Invalid regression model type: Choose 'random_forest', 'linear_regression', or 'gradient_boosting'.\")\n    elif learning_task_type == 'classification':\n        if model_type == 'random_forest':\n            model = RandomForestClassifier(**kwargs)\n        elif model_type == 'gradient_boosting':\n            model = GradientBoostingClassifier(**kwargs)\n        else:\n            raise ValueError(\"Invalid classification model type: Choose 'random_forest' or 'gradient_boosting'.\")\n    else:\n        raise ValueError(\"Learning types: ['classification','regression'] \\n Model types: ['linear_regression','random_forest','gradient_boosting']\")\n    model.fit(X_train, y_train)\n    return model\nCode\ndef tune(model, X_train, y_train, param_grid, scoring=None):\n    \"\"\"Performs hyper-parameter tuning.\"\"\"\n    grid_search = GridSearchCV(model, param_grid, scoring=scoring, cv=5, n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n    model = grid_search.best_estimator_\n    print(f\"Best params: {grid_search.best_params_}\")\n    return model\nCode\ndef validation_eval(learning_task_type, model, X_val, y_val):\n    y_pred = model.predict(X_val)\n\n    if learning_task_type == 'regression':\n        MAE = mean_absolute_error(y_val, y_pred)\n        RMSE = np.sqrt(mean_squared_error(y_val, y_pred))\n        R2 = r2_score(y_val, y_pred)\n\n        print(f\"Mean Absolute Error (MAE): {MAE:.4f}\")\n        print(f\"Root Mean Squared Error (RMSE): {RMSE:.4f}\")\n        print(f\"R-squared: {R2:.4f}\")\n    \n    elif learning_task_type == 'classification':\n        cm = confusion_matrix(y_val, y_pred)\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n        plt.xlabel('Predicted Labels')\n        plt.ylabel('True Labels')\n        plt.title('Confusion Matrix')\n        plt.show()\n    \n    else:\n        raise ValueError(\"Unsupported learning task type: 'regression' or 'classification'\")\n\n    return y_pred\nCode\ndef evaluate_test(learning_task_type, model, X_test, y_test):\n    \"\"\"Evaluates the model on new data or the test set.\"\"\"\n    y_pred = model.predict(X_test)\n    \n    if learning_task_type == 'regression':\n        MAE = mean_absolute_error(y_test, y_pred)\n        RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n        R2 = r2_score(y_test, y_pred)\n\n        print(f\"Mean Absolute Error (MAE): {MAE:.4f}\")\n        print(f\"Root Mean Squared Error (RMSE): {RMSE:.4f}\")\n        print(f\"R-squared: {R2:.4f}\")\n        \n    elif learning_task_type == 'classification':\n        print(\"Classification Report:\", classification_report(y_test, y_pred))\n    else:\n        raise ValueError(\"Unsupported learning task type: 'regression' or 'classification'\")\n    \n    return y_pred\nCode\nrf_param_grid = {\n    'n_estimators': [50, 100, 200],  \n    'max_depth': [5, 15, 20],  \n    'max_features': ['sqrt', 'log2'],  \n    'bootstrap': [True, False] \n}\n\nboost_param_grid = {\n    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n    'n_estimators': [50, 100, 200],  \n    'max_depth': [3, 5, 10], \n    'max_features': ['sqrt', 'log2']  \n}"
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#regression",
    "href": "technical-details/supervised-learning/main.html#regression",
    "title": "Supervised Learning",
    "section": "Regression",
    "text": "Regression\nRegression is a supervised learning task used to identify relationships between continuous data. In this task, there is one variable of interest, referred to as the dependent variable, and several independent features, which is hypothesized to be related to the dependent variable. The strength of these relationships is quantified by the coefficients of the independent variables.\nIn this case, our goal is to identify the drivers of chronic absenteeism. By analyzing these outputs, schools can implement targeted interventions to reduce chronic absenteeism in New York City Public Schools.\nTarget Variable: Percent of Students Chronically Absent\n\nLASSO Regression\nLASSO, or Least Absolute Shrinkage and Selection Operator is a regularization technique known as L1 Regularization. It is a good option in this case because of its ability to work with high dimensional data. One can think of it like a rope lasso that is thrown around all the features and filters out the variables that do not contribute to our model, by pushing their coefficients to 0. It does this by introducing a regularization hyperparamter, which will be tuned to help shrink the coefficicents. This will help us perform feature selection automatically, and find the importance of the terms that are left.\n\n\nCode\nX, y, X_train, X_val, X_test, y_train, y_val, y_test = preprocessing(df = df_clean, target_column='Percent of Students Chronically Absent')\n\n\n\n\nCode\nmodel = train(X_train, y_train, 'regression', 'lasso_regression', alpha=0.01)\ny_pred = validation_eval('regression', model,  X_val, y_val)\n\n\nMean Absolute Error (MAE): 0.1010\nRoot Mean Squared Error (RMSE): 0.1250\nR-squared: 0.3138\n\n\n\n\nCode\nplt.scatter(y_val, y_pred)\nplt.plot([min(y_val), max(y_val)], [min(y_pred), max(y_pred)], color='red', linestyle='--') \nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predicted Values\")\nplt.title(\"Parity Plot\")\nplt.show()\n\n\n\n\n\n\n\n\n\nTo tune the hyperparamter, I will use scikit-learn’s cross validation tool specifically for Lasso regression, LassoCV to find the optimal choice for alpha\n\n\nCode\nlasso_cv = LassoCV(alphas=[0.1, 0.01, 0.05, 0.001, 0.005, 0.0005, 0.0001], cv=5)\nlasso_cv.fit(X_train, y_train)\nprint(f\"Optimal alpha: {lasso_cv.alpha_}\")\n\n\nOptimal alpha: 0.005\n\n\n\n\nCode\nmodel = train(X_train, y_train, 'regression', 'lasso_regression', alpha=0.001)\ny_pred = evaluate_test('regression', model, X_test, y_test)\n\n\nMean Absolute Error (MAE): 0.0829\nRoot Mean Squared Error (RMSE): 0.1053\nR-squared: 0.6077\n\n\n\n\nCode\nplt.scatter(y_test, y_pred)\nplt.plot([min(y_test), max(y_test)], [min(y_pred), max(y_pred)], color='red', linestyle='--') \nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predicted Values\")\nplt.title(\"Parity Plot\")\nplt.show()\n\n\n\n\n\n\n\n\n\nNow, using the absolute value of the coefficients, we can visualize the features that are most relevant to the target variable\n\n\nCode\nfeature_names = X.columns\ncoefs = model.coef_\n\ncoefs_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefs})\n\n\ncoefs_df['abs_val_coef'] = coefs_df['Coefficient'].abs()\ncoefs_df = coefs_df.sort_values(by='abs_val_coef', ascending=False)\n\ncoefs_df = coefs_df.loc[coefs_df['abs_val_coef']&gt;0]\n\nplt.figure(figsize=(15, 15))\ncoefs_df.plot(kind='barh', x='Feature', y='abs_val_coef', legend=False)\nplt.xlabel('Absolute Value of Coefficient')\nplt.title('Feature Importance Based on Lasso Regression')\nplt.show()\n\n\n&lt;Figure size 2000x1500 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nResult: After tuning the alpha of the model, the fit improved to 61%, with a decrease in RMSE and MAE. In addition, valuable insights can be gained from the Feature Importance graph, with Supportive Environment score emerging as the most important variable in our model. This score reflects how well a school fosters a supportive, challenging environment for students1. The next most important feature is Average Grade 8 Proficiency. This metric emphasizes how important it is for children to be on the right track from a young age. The third key factor was Rigorous Instruction score, which reflects how engaging the curriculum and how effectively it promotes critial-thinking skills1. Additionally, significant socioeconomic factors contributing to chronic absenteeism included Percent English Language Learners and Percent in Temporary Housing.\n\n\nRandom Forest Regression\nRandom Forest is a supervised learning task that is an ensemble of many decision trees. Simply, decision trees work by starting at a root node and split depending on questions asked at each successive node. Random Forest is just many decision trees working together. It is superior to single decision trees because it prevents overfitting by averaging the outcome of the individual trees to get the final result. In addition, it is less sensitive to multicollinearity and normalization than other regression methods and can learn non-linear boundaries.\nThere are a few important hyperparamters to tune in random forest regression. This includes n_estimators (the number of trees in the forest), max_depth (the maximum depth or number of splits each tree can have), max_features (how many features are considered for splits), and bootstrap (whether bootstrapping (resampling with replacement) should be used)2\nWhen bootstrapping is used, this is considered a bagging method (Bootstrap Aggregating).\nI will apply the Random Forest Regressor and evaluate whether it improves our results.\n\n\nCode\nX, y, X_train, X_val, X_test, y_train, y_val, y_test = preprocessing(df_regression, 'Percent of Students Chronically Absent')\n\n\n\n\nCode\nmodel = train(X_train, y_train, 'regression', 'random_forest')\nprint('Validation Scores')\ny_pred = validation_eval('regression',model,  X_val, y_val)\n\n\nValidation Scores\nMean Absolute Error (MAE): 0.0860\nRoot Mean Squared Error (RMSE): 0.1136\nR-squared: 0.5295\n\n\n\n\nCode\nplt.scatter(y_val, y_pred)\nplt.plot([min(y_val), max(y_val)], [min(y_pred), max(y_pred)], color='red', linestyle='--') \nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predicted Values\")\nplt.title(\"Parity Plot\")\nplt.show()\n\n\n\n\n\n\n\n\n\nTune and Retrain Model\n\n\nCode\ntune(model, X_train, y_train, rf_param_grid, scoring='neg_mean_squared_error')\n\n\nBest params: {'bootstrap': True, 'max_depth': 15, 'max_features': 'log2', 'n_estimators': 200}\n\n\nRandomForestRegressor(max_depth=15, max_features='log2', n_estimators=200)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  RandomForestRegressor?Documentation for RandomForestRegressoriFittedRandomForestRegressor(max_depth=15, max_features='log2', n_estimators=200) \n\n\n\n\nCode\nmodel = train(X_train, y_train, 'regression', 'random_forest', bootstrap = True, max_depth= 15, max_features= 'log2', n_estimators= 200)\n\n\n\n\nCode\nprint('Test Evaluation')\ny_pred = evaluate_test('regression', model, X_test, y_test)\n\n\nTest Evaluation\nMean Absolute Error (MAE): 0.0851\nRoot Mean Squared Error (RMSE): 0.1049\nR-squared: 0.5415\n\n\n\n\nCode\nplt.scatter(y_test, y_pred)\nplt.plot([min(y_test), max(y_test)], [min(y_pred), max(y_pred)], color='red', linestyle='--') \nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predicted Values\")\nplt.title(\"Parity Plot\")\nplt.show()\n\n\n\n\n\n\n\n\n\nA handy output of Random Forest is feature importance. Now it is evident which features are most important to our target variable.\n\n\nCode\nfeature_importances = model.feature_importances_\nfeature_names = X.columns\n\nimportance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n\n\n\n\nCode\nplt.figure(figsize=(10, 6))\nimportance_df.plot(kind='barh', x='Feature', y='Importance', legend=False)\nplt.xlabel('Importance')\nplt.title('Feature Importance Based on Random Forest Regression')\nplt.show()\n\n\n&lt;Figure size 1000x600 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nResults: Our tuned Random Forest model performed slightly better than the original but did not outperform the LASSO regression. Nonetheless, I can still evaluate the feature importance from the Random Forest and compare it to previous models. Average Grade 8 Proficiency and Supportive Environment scores remain in the top 3 most important features. Additionally, ‘Percent College Ready based on SAT Math’ has emerged as a key feature. This suggests that SAT Math scores are an indicator of chronic absenteeism—students who attend school regularly are more likely to be college-ready based on their SAT performance.\n\n\nGradient Boosting Regression\nI will try one more regression algorithm to see if it can improve our results.\nUnlike the previous bagging method, I will now employ a boosting technique. In boosting, trees are grown sequentially rather than in parallel, as in bagging. This approach uses random sampling with replacement over weighted data, enabling each tree to learn from the errors of the previous models. By aggregating these weak learners into a strong learner, boosting optimizes the overall model performance.\nThe important hyperparameters to tune in gradient boosting are learning rate (controls for the contribution of each tree), n_estimators (number of trees), max_depth (controls number of nodes in the tree), and max_features (number of features to consider for splits)3\n\n\nCode\nX, y, X_train, X_val, X_test, y_train, y_val, y_test = preprocessing(df_regression, 'Percent of Students Chronically Absent')\n\n\n\n\nCode\nmodel = train(X_train, y_train, 'regression', 'gradient_boosting')\ny_pred = validation_eval('regression', model,  X_val, y_val)\n\n\nMean Absolute Error (MAE): 0.0781\nRoot Mean Squared Error (RMSE): 0.0967\nR-squared: 0.5203\n\n\n\n\nCode\nplt.scatter(y_val, y_pred)\nplt.plot([min(y_val), max(y_val)], [min(y_pred), max(y_pred)], color='red', linestyle='--') \nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predicted Values\")\nplt.title(\"Parity Plot\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel = tune(model, X_train, y_train, boost_param_grid, scoring='neg_mean_squared_error')\n\n\nBest params: {'learning_rate': 0.05, 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 100}\n\n\n\n\nCode\nmodel = train(X_train, y_train, 'regression', 'gradient_boosting', learning_rate= 0.05, max_depth= 10, max_features= 'log2', n_estimators= 100)\nprint('Validation Scores')\ny_pred = validation_eval('regression', model,  X_val, y_val)\n\n\nValidation Scores\nMean Absolute Error (MAE): 0.0742\nRoot Mean Squared Error (RMSE): 0.0941\nR-squared: 0.5461\n\n\n\n\nCode\nprint('Test Evaluation')\ny_pred = evaluate_test('regression', model, X_test, y_test)\n\n\nTest Evaluation\nMean Absolute Error (MAE): 0.0978\nRoot Mean Squared Error (RMSE): 0.1209\nR-squared: 0.5147\n\n\n\n\nCode\nplt.scatter(y_test, y_pred)\nplt.plot([min(y_test), max(y_test)], [min(y_pred), max(y_pred)], color='red', linestyle='--') \nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predicted Values\")\nplt.title(\"Parity Plot\")\nplt.show()\n\n\n\n\n\n\n\n\n\nResult: The tuned gradient boosting model shows slight improvement over the original but does not perform as well on the test data. Both the LASSO and Random Forest Regression models outperformed it, suggesting that gradient boosting may not be the best fit for this dataset."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#binary-classification",
    "href": "technical-details/supervised-learning/main.html#binary-classification",
    "title": "Supervised Learning",
    "section": "Binary Classification",
    "text": "Binary Classification\nBinary classification is a supervised learning algorithm used for predicting categorical variables with two possible classes. The goal is to train a model that accurately predicts the correct class labels as much as possible. The output of a classification task is best evaluated using a confusion matrix, which provides insights into the model’s performance. From the confusion matrix, one can calculate key metrics such as accuracy, precision, recall, and F1 score. The choice of the metric to maximize depends on the specific classification problem.\nThe calculations are as follows: \\[\n\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n\\] \\[\n\\text{Precision} = \\frac{TP}{TP + FP}\n\\] \\[\n\\text{Recall} = \\frac{TP}{TP + FN}\n\\] F1 is the harmonic balance of precision and recall, calculated as: \\[\n\\text{F1} = \\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n\\]\nTarget variable: High Schools with high vs. low dropout risk\nIn this case, accuracy is not an ideal metric because our classes are imbalanced. The worst-case scenario is failing to identify a school as having high dropout risk. If “high schools with high dropout risk” is treated as the positive class as, the aim is to minimize false negatives (Type II errors) and maximize the recall score. To achieve this, cross-validation will be used to identify the algorithm that performs best for our objective.\nFirst, I will create a binary variable for high dropout risk. High-risk schools will be defined as those in the 75th percentile or above of the dropout rate distribution. Additionally, I will exclude the “Graduation Rate” feature to avoid data leakage.\n\n\nCode\nprint(df_clean['dropout_rate'].describe())\n\n\ncount    501.000000\nmean       0.053580\nstd        0.052614\nmin        0.000000\n25%        0.012250\n50%        0.037000\n75%        0.077000\nmax        0.276500\nName: dropout_rate, dtype: float64\n\n\n\n\nCode\ndf_class = df_clean.copy()\ndf_class['high_dropout'] = [1 if x &gt;= .077 else 0 for x in df_class['dropout_rate']]\ndf_class.drop(['dropout_rate','Graduation Rate'], axis=1, inplace=True)\n\n\n\nRandom Forest Classification\nI will begin by using a Random Forest classifier. This method is similar to the Random Forest regressor explored earlier, but instead of predicting continuous variables, the trees now predict the class to which the data belongs. In Random Forest classification, the final prediction is determined by a majority vote among all the decision trees in the ensemble, rather than taking the average as in regression.\nSince our minorty class is imbalanced I will use SMOTE (Synthetic Minority Over-sampling Technique) to over sample the minority class. This will balance the data and create a more robust model.\n\n\nCode\nX, y, X_train, X_val, X_test, y_train, y_val, y_test = preprocessing(df = df_class, target_column='high_dropout')\n\n\n\n\nCode\nsmote = SMOTE(sampling_strategy='auto')\nX_smote, y_smote = smote.fit_resample(X_train, y_train)\n\n\n\n\nCode\nmodel = train(X_smote, y_smote, 'classification', 'random_forest')\ny_pred = validation_eval('classification',model,  X_val, y_val)\n\n\n\n\n\n\n\n\n\n\n\nCode\ny_pred = evaluate_test('classification', model, X_test, y_test)\n\n\nClassification Report:               precision    recall  f1-score   support\n\n           0       0.91      0.83      0.87        75\n           1       0.61      0.77      0.68        26\n\n    accuracy                           0.81       101\n   macro avg       0.76      0.80      0.77       101\nweighted avg       0.83      0.81      0.82       101\n\n\n\n\n\nCode\nmodel = tune(model, X_train, y_train, rf_param_grid, scoring='f1')\n\n\nBest params: {'bootstrap': False, 'max_depth': 15, 'max_features': 'sqrt', 'n_estimators': 50}\n\n\n\n\nCode\nmodel = train(X_smote, y_smote, 'classification', 'random_forest', bootstrap=False, max_depth=15, max_features='sqrt', n_estimators=50)\ny_pred = validation_eval('classification', model,  X_val, y_val)\n\n\n\n\n\n\n\n\n\n\n\nCode\ny_pred = evaluate_test('classification', model, X_test, y_test)\n\n\nClassification Report:               precision    recall  f1-score   support\n\n           0       0.89      0.88      0.89        75\n           1       0.67      0.69      0.68        26\n\n    accuracy                           0.83       101\n   macro avg       0.78      0.79      0.78       101\nweighted avg       0.83      0.83      0.83       101\n\n\n\nResult: The tuned Random Forest Classifier showed only a slight improvement upon the base model. Since it is necessary to prioritize recall, to avoid overlooking schools with high dropout risk, this model correctly identifies 88% of schools with low dropout risk but only 69% of schools with high dropout risk. This suggests that there is room for improvement. Next, I will explore alternative classification algorithms to achieve better recall for high-risk schools.\n\n\nGradient Boosting Classification\nNext, I will use a Gradient Boosting Classifier. This method is similar to the Gradient Boosting Regressor tried earlier, but instead of predicting continuous values, the trees are trained to classify the data into predefined classes.\n\n\nCode\nX, y, X_train, X_val, X_test, y_train, y_val, y_test = preprocessing(df = df_class, target_column='high_dropout')\n\n\n\n\nCode\nsmote = SMOTE(sampling_strategy='auto')\nX_smote, y_smote = smote.fit_resample(X_train, y_train)\n\n\n\n\nCode\nmodel = train(X_smote, y_smote, 'classification', 'gradient_boosting')\ny_pred = validation_eval('classification',model,  X_val, y_val)\n\n\n\n\n\n\n\n\n\n\n\nCode\ny_pred = evaluate_test('classification', model, X_test, y_test)\n\n\nClassification Report:               precision    recall  f1-score   support\n\n           0       0.96      0.89      0.92        79\n           1       0.68      0.86      0.76        22\n\n    accuracy                           0.88       101\n   macro avg       0.82      0.87      0.84       101\nweighted avg       0.90      0.88      0.89       101\n\n\n\n\n\nCode\nmodel = tune(model, X_train, y_train, boost_param_grid, scoring='f1')\n\n\nBest params: {'learning_rate': 0.2, 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 100}\n\n\n\n\nCode\nmodel = train(X_smote, y_smote, 'classification', 'gradient_boosting', learning_rate =0.2, max_depth=3, max_features='log2', n_estimators=100)\ny_pred = validation_eval('classification', model,  X_val, y_val)\n\n\n\n\n\n\n\n\n\n\n\nCode\ny_pred = evaluate_test('classification', model, X_test, y_test)\n\n\nClassification Report:               precision    recall  f1-score   support\n\n           0       0.97      0.89      0.93        79\n           1       0.69      0.91      0.78        22\n\n    accuracy                           0.89       101\n   macro avg       0.83      0.90      0.86       101\nweighted avg       0.91      0.89      0.90       101\n\n\n\n\n\nCode\nfeature_importances = model.feature_importances_\nfeature_names = X.columns\n\nimportance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False).head(15)\n\nplt.figure(figsize=(10, 6))\nimportance_df.plot(kind='barh', x='Feature', y='Importance', legend=False)\nplt.xlabel('Importance')\nplt.title('Top 15 Features')\nplt.show()\n\n\n&lt;Figure size 1000x600 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nResult: The tuned gradient boosting model effectively predicts high and low dropout risk for high schools, outperforming the Random Forest model. Since recall is prioritized (to avoid overlooking schools with high dropout risk), this model performs well, correctly identifying 89% of schools with low dropout risk and 91% of schools with high dropout risk. These results suggest that it is possible to identify key drivers of dropout risk and intervene accordingly.\nThe top 15 important features highlight several key factors, with college persistence ranking the highest. This suggests that schools struggling with dropout risk may also have issues with retaining students after their first year of college. Other significant features include percent of students in temporary housing and percent of overage/undercredited students (students with very few credits), which indicates a strong relationship between socioeconomic challenges and dropout rates."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#multiclass-classification",
    "href": "technical-details/supervised-learning/main.html#multiclass-classification",
    "title": "Supervised Learning",
    "section": "Multiclass Classification",
    "text": "Multiclass Classification\nMulticlass classification is similar to binary classification, but instead of predicting between two classes, there are now three or more classes. In this case, the interest is classifying high schools based on their rates of college persistence, which will be categorized as low, medium, or high.\nIn our binary classification, the focus was identifying high schools with a high dropout risk rate. However, even if a high school is deemed “safe” with low dropout risk, it is still necessary to intervene if the school has low college persistence rates. While preventing high school dropout is a significant achievement, it is also important to translate efforts into preventing dropouts from higher education.\nTarget Variable: College Persistence\nFirst, I will divide the college persistence distribution into three bins, labeling them as Low, Medium, and High. I will again use SMOTE to address class imbalance.\n\n\nCode\ndf_multi = df_clean.copy()\ndf_multi['college_persistence_ranking'] = pd.cut(df_multi['Metric Value - College Persistence'], bins=3, labels=['Low','Medium','High'])\ndf_multi.drop(['Metric Value - College Persistence'], axis=1, inplace=True)\n\n\n\nRandom Forest Classifier\nI will test how well a Random Forest Classifier predicts our labels, this time for three classes\n\n\nCode\nX, y, X_train, X_val, X_test, y_train, y_val, y_test = preprocessing(df = df_multi, target_column='college_persistence_ranking')\n\n\n\n\nCode\nsmote = SMOTE(sampling_strategy='auto')\nX_smote, y_smote = smote.fit_resample(X_train, y_train)\n\n\n\n\nCode\nmodel = train(X_smote, y_smote, 'classification', 'random_forest')\ny_pred = validation_eval('classification',model,  X_val, y_val)\n\n\n\n\n\n\n\n\n\n\n\nCode\ny_pred = evaluate_test('classification', model, X_test, y_test)\n\n\nClassification Report:               precision    recall  f1-score   support\n\n        High       0.63      0.77      0.69        22\n         Low       0.61      0.64      0.62        22\n      Medium       0.75      0.67      0.70        57\n\n    accuracy                           0.68       101\n   macro avg       0.66      0.69      0.67       101\nweighted avg       0.69      0.68      0.68       101\n\n\n\n\n\nCode\nmodel = tune(model, X_train, y_train, rf_param_grid)\n\n\nBest params: {'bootstrap': True, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 50}\n\n\n\n\nCode\nmodel = train(X_smote, y_smote, 'classification', 'random_forest', bootstrap=True, max_depth=5, max_features='sqrt', n_estimators=50)\ny_pred = validation_eval('classification', model,  X_val, y_val)\n\n\n\n\n\n\n\n\n\n\n\nCode\ny_pred = evaluate_test('classification', model, X_test, y_test)\n\n\nClassification Report:               precision    recall  f1-score   support\n\n        High       0.64      0.82      0.72        22\n         Low       0.66      0.86      0.75        22\n      Medium       0.84      0.65      0.73        57\n\n    accuracy                           0.73       101\n   macro avg       0.71      0.78      0.73       101\nweighted avg       0.76      0.73      0.73       101\n\n\n\nResult: The tuned Random Forest Classifier showed a slight improvement upon the base model in predicting instances of high and low rates of college persistence but performed worse for schools with medium rates, identifying only 65% of them. I hypothesize that similar to binary classification, the gradient boosted will improve upon this performance.\n\n\nGradient Boosting\nNow I will attempt a Gradient Boosting Classifier and see if it improves upon the Random Forest Classifier\n\n\nCode\nX, y, X_train, X_val, X_test, y_train, y_val, y_test = preprocessing(df = df_multi, target_column='college_persistence_ranking')\n\n\n\n\nCode\nsmote = SMOTE(sampling_strategy='auto')\nX_smote, y_smote = smote.fit_resample(X_train, y_train)\n\n\n\n\nCode\nmodel = train(X_smote, y_smote, 'classification', 'gradient_boosting')\ny_pred = validation_eval('classification',model,  X_val, y_val)\n\n\n\n\n\n\n\n\n\n\n\nCode\ny_pred = evaluate_test('classification', model, X_test, y_test)\n\n\nClassification Report:               precision    recall  f1-score   support\n\n        High       0.55      0.86      0.67        14\n         Low       0.61      0.86      0.72        22\n      Medium       0.90      0.66      0.76        65\n\n    accuracy                           0.73       101\n   macro avg       0.68      0.79      0.71       101\nweighted avg       0.79      0.73      0.74       101\n\n\n\n\n\nCode\nmodel = tune(model, X_train, y_train, boost_param_grid)\n\n\nBest params: {'learning_rate': 0.05, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 100}\n\n\n\n\nCode\nmodel = train(X_smote, y_smote, 'classification', 'gradient_boosting', learning_rate = 0.05, max_depth=3, max_features='sqrt', n_estimators=100)\ny_pred = validation_eval('classification', model,  X_val, y_val)\n\n\n\n\n\n\n\n\n\n\n\nCode\ny_pred = evaluate_test('classification', model, X_test, y_test)\n\n\nClassification Report:               precision    recall  f1-score   support\n\n        High       0.60      0.86      0.71        14\n         Low       0.67      0.91      0.77        22\n      Medium       0.92      0.72      0.81        65\n\n    accuracy                           0.78       101\n   macro avg       0.73      0.83      0.76       101\nweighted avg       0.82      0.78      0.79       101\n\n\n\n\n\nCode\nfeature_importances = model.feature_importances_\nfeature_names = X.columns\n\nimportance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False).head(15)\n\nplt.figure(figsize=(10, 6))\nimportance_df.plot(kind='barh', x='Feature', y='Importance', legend=False)\nplt.xlabel('Importance')\nplt.title('Top 15 Features')\nplt.show()\n\n\n&lt;Figure size 1000x600 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nResult Examining the recall scores, this gradient boosting multiclass classification model successfully predicts 86% of schools with high college persistence, 72% of schools with medium college persistence, and 91% of schools with low college persistence. While there is room for improvement in predicting the medium category, the model’s ability to accurately identify schools with low college persistence is particularly significant, as this is where where intervention is most needed. This model performed better than the Random Forest Classifier\nLooking at the feature importance, as seen in the regression on chronic absenteeism model, Average Grade 8 Proficiency is the most important driver of college persistence. It is noteworthy that this metric continues to have predictive power at the college level. Additionally, both dropout rate and the percentage of chronically absent students are significant features in this model, highlighting the deep-rooted issues within schools that must be addressed.\n\n\nConclusion\nThe results across all models provide consistent and valuable insights into the factors driving student outcomes such as chronic absenteeism, dropout risk, and college persistence in high schools. Key predictors include Average Grade 8 Proficiency, Supportive Environment score, and Rigorous Instruction score were found in multiple models, showing the importance of academic foundations, school culture, and quality instruction. Socioeconomic indicators, such as the Percent of Students in Temporary Housing, Percent of English Language Learners, and Percent of Overage/Undercredited Students, further emphasize the impact of systemic challenges on educational outcomes.\nModel Summary: * Regression: LASSO performed best, with a 61% fit and outperforming Random Forest and Gradient Boosting models. * Binary Classification: The Gradient Boosting model effectively identified 91% of schools with high dropout risk. * Multiclass Classification: The Gradient Boosting multiclass model accurately predicted 86% of schools with high college persistence and 91% of schools with low college persistence, where intervention is most critical. * Note: Random Forest models showed slight improvements with tuning, but underperformed compared to Gradient Bosting.\nIn conclusion, these results highlight actionable insights for improving student outcomes. Initiatives need to strengthen academic foundations in early education, foster supportive school environments, and address socioeconomic challenges. Models with strong recall, can serve as valuable tools for identifying schools in need of intervention and targeting resources where they are most needed."
  },
  {
    "objectID": "technical-details/data-collection/main.html",
    "href": "technical-details/data-collection/main.html",
    "title": "Data Collection",
    "section": "",
    "text": "The goal of this section is to collect and consolidate data to build a comprehensive dataset that captures factors influencing negative high school outcomes in New York City. This includes data on high school offerings, quality metrics, and socioeconomic characteristics.\n\n\n\nCompile relevant data from multiple sources to understand key drivers behind poor high school outcomes.\nCreate a unified dataset that combines academic quality indicators, attendance statistics, and socioeconomic factors for further analysis.\n\n\n\n\nHigh school outcomes, such as chronic absenteeism, dropping out, and low college persistence rates, can significantly impact students futures. By identifying the underlying factors driving these outcomes, this analysis seeks to provide actionable insights that could inform policies or interventions aimed at improving educational equity and student success in New York City high schools.\n\n\n\n\nAggregate and map data from various sources, including high school quality reports and Census data, into one unified dataset.\nEnsure compatibility between datasets by creating shared columns through location metrics, for example ZIP code.\nLay the groundwork for further analysis, enabling the exploration of correlations between school quality, socioeconomic factors, and student outcomes."
  },
  {
    "objectID": "technical-details/data-collection/main.html#overview",
    "href": "technical-details/data-collection/main.html#overview",
    "title": "Data Collection",
    "section": "",
    "text": "The goal of this section is to collect and consolidate data to build a comprehensive dataset that captures factors influencing negative high school outcomes in New York City. This includes data on high school offerings, quality metrics, and socioeconomic characteristics.\n\n\n\nCompile relevant data from multiple sources to understand key drivers behind poor high school outcomes.\nCreate a unified dataset that combines academic quality indicators, attendance statistics, and socioeconomic factors for further analysis.\n\n\n\n\nHigh school outcomes, such as chronic absenteeism, dropping out, and low college persistence rates, can significantly impact students futures. By identifying the underlying factors driving these outcomes, this analysis seeks to provide actionable insights that could inform policies or interventions aimed at improving educational equity and student success in New York City high schools.\n\n\n\n\nAggregate and map data from various sources, including high school quality reports and Census data, into one unified dataset.\nEnsure compatibility between datasets by creating shared columns through location metrics, for example ZIP code.\nLay the groundwork for further analysis, enabling the exploration of correlations between school quality, socioeconomic factors, and student outcomes."
  },
  {
    "objectID": "technical-details/data-collection/main.html#methods",
    "href": "technical-details/data-collection/main.html#methods",
    "title": "Data Collection",
    "section": "Methods",
    "text": "Methods\n\nAmerican Community Survey API\nIn the following code, I first used the requests library to retrieve the Census data from the American Community Survey. The params include get and for, which specify the columns of interest and to pull data at the zip code level, respectively. Chat GPT was used to brainstorm potentional relevant columns to pull from the 10,000+ columns that would satisfy the project objectives1. I stored this in a pandas dataframe and renamed the columns to ensure readability. Finally, I exported this dataframe to a csv file to prepare for data cleaning.\n\nimport requests\nimport pandas as pd\n\n\n# base url + specifiy params\nurl = \"https://api.census.gov/data/2022/acs/acs5/profile\"\nparams = {\n    \"get\": \"DP02_0060PE,DP02_0068PE,DP02_0114PE,DP02_0072PE,DP02_0094PE,DP02_0154PE,DP03_0062E,DP03_0074PE\",\n    \"for\": \"zip code tabulation area:*\",\n    \"key\": \"1c6835368d6cc1f7472ed2e8a39e07ee7e9d1cd6\"\n}\n\nresponse = requests.get(url, params=params)\n\n# check the response\nif response.status_code == 200:\n    data = response.json()\n    df = pd.DataFrame(data[1:], columns=data[0])\n\n    df.rename(columns={\n    \"DP02_0060PE\": \"Percent No High School (25+)\",\n    \"DP02_0068PE\": \"Percent Bachelor's Degree or Higher (25+)\",\n    \"DP02_0114PE\": \"Percent Language Other Than English at Home\",\n    \"DP02_0072PE\": \"Percent Population with Disabilities\",\n    \"DP02_0094PE\": \"Percent Foreign-Born Population\",\n    \"DP02_0154PE\": \"Percent Households with Broadband Internet\",\n    \"DP03_0062E\": \"Median Household Income\",\n    \"DP03_0074PE\": \"Percent Households on SNAP/Food Stamps\"\n    }, inplace=True)\n\n    print(df)\nelse:\n    print(f\"Error: {response.status_code} - {response.text}\")\n\n      Percent No High School (25+) Percent Bachelor's Degree or Higher (25+)  \\\n0                             None                                      None   \n1                             None                                      None   \n2                             None                                      None   \n3                             None                                      None   \n4                             None                                      None   \n...                            ...                                       ...   \n33769                          0.0                                      64.0   \n33770                          3.0                                      17.0   \n33771                          0.9                                       9.2   \n33772                          0.0                                       0.0   \n33773                          1.7                                      18.0   \n\n      Percent Language Other Than English at Home  \\\n0                                            None   \n1                                            None   \n2                                            None   \n3                                            None   \n4                                            None   \n...                                           ...   \n33769                                         0.0   \n33770                                         5.2   \n33771                                         4.9   \n33772                                       100.0   \n33773                                         4.6   \n\n      Percent Population with Disabilities Percent Foreign-Born Population  \\\n0                                     None                            None   \n1                                     None                            None   \n2                                     None                            None   \n3                                     None                            None   \n4                                     None                            None   \n...                                    ...                             ...   \n33769                                 36.0                             0.0   \n33770                                 21.0                             3.2   \n33771                                 24.7                             2.6   \n33772                                100.0                           100.0   \n33773                                 23.1                             3.8   \n\n      Percent Households with Broadband Internet Median Household Income  \\\n0                                           None                   17526   \n1                                           None                   20260   \n2                                           None                   17703   \n3                                           None                   19603   \n4                                           None                   22796   \n...                                          ...                     ...   \n33769                                       64.0              -666666666   \n33770                                       64.7                   80313   \n33771                                       75.4                   78365   \n33772                                      100.0              -666666666   \n33773                                       81.1                   61125   \n\n      Percent Households on SNAP/Food Stamps zip code tabulation area  \n0                                       57.9                    00601  \n1                                       57.0                    00602  \n2                                       53.3                    00603  \n3                                       58.5                    00606  \n4                                       55.4                    00610  \n...                                      ...                      ...  \n33769                                    0.0                    99923  \n33770                                    9.4                    99925  \n33771                                   28.0                    99926  \n33772                                    0.0                    99927  \n33773                                   13.4                    99929  \n\n[33774 rows x 9 columns]\n\n\nExport to csv\n\ndf.to_csv('../../data/raw-data/ACS_data.csv')\n\n\n\nNYC Open Data API\nThis data on graduation rate outcomes is taken from NYC Open Data. This file contains the dropout rates of interest. This code is adapted from the API documentation2. The library Socrata from sodapy is used to retrieve the data. The package returns the JSON data to a Python list of dictionaries for easy conversion to a pandas dataframe.\n\nfrom sodapy import Socrata\n\n# unauthenticated client works with public data sets\n\nclient = Socrata(\"data.cityofnewyork.us\", None)\nresults = client.get(\"mjm3-8dw8\", limit=321002)\n\n# convert to pandas df\nresults_df = pd.DataFrame.from_records(results)\n\nWARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n\n\nExport to csv\n\nresults_df.to_csv('../../data/raw-data/dropout_data.csv')\n\n\n\nOther Datasets\nTo gather data on the quality of each high school in New York City, including some of my targets of interest, such as chronic absenteeism and college persistence, I downloaded an xlsx dataset from NYC InfoHub.\nDownload the 2022-23 High School Quality Report\nAdditionally, to map the quality data to Census data, I used an NYC High School Directory file available on the InfoHub site. This file provided ZIP codes, which enabled me to join the quality data with Census data.\nDownload the mapping file"
  },
  {
    "objectID": "technical-details/data-collection/main.html#takeaways",
    "href": "technical-details/data-collection/main.html#takeaways",
    "title": "Data Collection",
    "section": "Takeaways",
    "text": "Takeaways\n\nSummary\nThis section focuses on collecting and integrating data to build a comprehensive dataset that explores the factors influencing negative high school outcomes in New York City. Using data from NYC InfoHub and Census mapping, I was able to create a unified and actionable dataset that will provides insights for improving educational equity and student success. This foundational work enables deeper analysis to inform strategies and interventions for better high school outcomes.\n\n\nChallenges\nOne major challenge I faced was finding data that could be aggregated into my dataset. The NYC high school quality data is organized by school name and DBN, a unique New York identifier that combines the district, borough, and NYC DOE school number. However, many other datasets, such as nationwide ones that I was interested in, did not include these identifiers, as they are specific to New York. As a result, I had to spend considerable time finding data with compatible aggregations, which somewhat limited my options. Eventually, I was able to find a mapping of DBN to ZIP code, which allowed me to incorporate census data into my school data, adding a few socioeconomic factors.\nFor future work, I would be interested in scaling this project to include all of New York State or even nationwide data. Currently, my analysis is limited to New York City high schools, resulting in a dataset of only about 500 rows, which is relatively small. Expanding to a larger dataset with more schools would likely enable the creation of more robust datasets and models.\n\n\nConclusion and Future Steps\nBy aggregating data from three different datasets, a comprehensive dataset is created to evaluate various features that may impact our target variables. This analysis helps us better understand how high school quality and socioeconomic factors influence high school outcomes in New York City. Next steps involve cleaning and exploring this data in order to prepare it for the modeling phase."
  },
  {
    "objectID": "technical-details/data-cleaning/main.html",
    "href": "technical-details/data-cleaning/main.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "The data cleaning phase is a crucial and often time-consuming part of any machine learning project. The dataset I am working with contains over 600 columns, which need to be narrowed down to the most relevant ones for analysis. Preparing the data carefully is essential for successful exploratory data analysis (EDA) and modeling. During the process, new issues often arise, particularly when working with large datasets where it’s impossible to anticipate every challenge upfront. This is why data cleaning is considered an iterative process that evolves as the project progresses.\nTo ensure the data is cleaned accurately, I relied on the NYC Public Schools’ School Quality Reports Educator Guide: High Schools 2022–231 as a data dictionary. This guide helped me understand the meaning behind many of the columns, allowing me to clean and organize the data effectively for future analysis.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sodapy import Socrata\nfrom scipy.stats import skew\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('future.no_silent_downcasting', True)\n\nRead in data\n\nquality_tabs = pd.read_excel('../../data/raw-data/202223-hs-sqr-results.xlsx', skiprows=3, nrows=506, sheet_name=None)\nACS_df = pd.read_csv('../../data/raw-data/ACS_data.csv')\ndropout_df = pd.read_csv('../../data/raw-data/dropout_data.csv', index_col=None)\nmapping_df = pd.read_csv('../../data/mapping/2021_DOE_High_School_Directory.csv', index_col=None)\n\nConcat 4 dicts of quality sheets, remove first row, drop duplicated columns\n\ndf_quality = pd.concat(quality_tabs.values(), axis=1)\n\ndf_quality = df_quality.iloc[1: , :]\n\ndf_quality = df_quality.loc[:, ~df_quality.T.duplicated(keep='first')]\n\nGet columns needed from mapping, add zip code to df\n\n#get columns \ndf_mapping = mapping_df[['dbn','postcode']]\ndf_mapping.rename(columns={\"dbn\": \"DBN\", \"postcode\": \"zip code\"}, inplace=True)\n#add zip code to df\ndf = df_quality.merge(df_mapping, on='DBN', how='left')\n\nFind missing zip codes and export as csv\n\nmissing_school_zips = df.loc[df['zip code'].isna()]\nmissing_school_zips[['DBN', 'School Name']].drop_duplicates().to_csv('../../data/mapping/missing_list.csv', index=False)\n\nManually impute zip codes and read back in filled df\n\nmap2 = pd.read_csv('../../data/mapping/missing_list_labeled.csv')\n\nMerge again and fill in missing zip codes\n\ndf = df.merge(map2, on='DBN', how='left')\ndf['zip code'] = df['zip code'].fillna(df['zipcode1'])\ndf.drop(columns=['school_name1', 'zipcode1'],inplace=True)\n\nAdd in ACS data\n\nACS_df['zip code tabulation area'] = pd.to_numeric(ACS_df['zip code tabulation area'])\nACS_df.rename(columns={\"zip code tabulation area\": \"zip code\"}, inplace=True)\ndf = df.merge(ACS_df, on='zip code', how='left')\n\nClean the columns needed from dropout df, filter for 2018 cohort year - which will match up with 2022-23 data, filter school and student type\n\ndropout_df = dropout_df.loc[dropout_df['cohort_year']==2018]\ndropout_df = dropout_df.loc[dropout_df['report_category'].str.contains('School')]\ndropout_df = dropout_df.loc[dropout_df['category']=='All Students']\n\ndropout_df = dropout_df[['geographic_subdivision','category','school_name','dropout_1']]\n\nCalculate mean dropout rate per school\n\ndropout_df['dropout_1'] = pd.to_numeric(dropout_df['dropout_1'], errors='coerce')\ntransformed_df = dropout_df.groupby(['geographic_subdivision','category','school_name']).transform('mean')\ndropout_df = pd.concat([dropout_df[['geographic_subdivision', 'category', 'school_name']], transformed_df], axis=1)\ndropout_df = dropout_df.drop_duplicates()\ndropout_df.rename(columns={\"dropout_1\": \"dropout_rate\", \"school_name\":\"School Name\"}, inplace=True)\ndropout_df = dropout_df[['School Name','dropout_rate']]\n\nMerge to final dataframe\n\ndropout_df['School Name'] = dropout_df['School Name'].str.lower()\ndf['School Name'] = df['School Name'].str.lower()\ndf = df.merge(dropout_df, on='School Name', how='left')\n\nPre cleaning df.head check\n\ndf.head()\n\n\n\n\n\n\n\n\nUnnamed: 0_x\nDBN\nSchool Name\nSchool Type\nEnrollment\nRigorous Instruction Rating\nCollaborative Teachers Rating\nSupportive Environment Rating\nEffective School Leadership Rating\nStrong Family-Community Ties Rating\n...\nUnnamed: 0_y\nPercent No High School (25+)\nPercent Bachelor's Degree or Higher (25+)\nPercent Language Other Than English at Home\nPercent Population with Disabilities\nPercent Foreign-Born Population\nPercent Households with Broadband Internet\nMedian Household Income\nPercent Households on SNAP/Food Stamps\ndropout_rate\n\n\n\n\n0\nNaN\n01M292\norchard collegiate academy\nHigh School\n269.0\nMeeting Target\nExceeding Target\nMeeting Target\nMeeting Target\nApproaching Target\n...\n2578.0\n16.2\n38.1\n53.0\n13.0\n38.1\n76.1\n43362.0\n34.0\n3.3\n\n\n1\nNaN\n01M448\nuniversity neighborhood high school\nHigh School\n485.0\nExceeding Target\nExceeding Target\nExceeding Target\nExceeding Target\nMeeting Target\n...\n2578.0\n16.2\n38.1\n53.0\n13.0\n38.1\n76.1\n43362.0\n34.0\n2.9\n\n\n2\nNaN\n01M450\neast side community school\nHigh School\n389.0\nExceeding Target\nExceeding Target\nExceeding Target\nExceeding Target\nExceeding Target\n...\n2584.0\n7.0\n62.3\n34.6\n14.0\n24.3\n85.3\n83344.0\n18.0\n0.0\n\n\n3\nNaN\n01M539\nnew explorations into science, technology and ...\nHigh School\n620.0\nMeeting Target\nMeeting Target\nExceeding Target\nExceeding Target\nExceeding Target\n...\n2578.0\n16.2\n38.1\n53.0\n13.0\n38.1\n76.1\n43362.0\n34.0\n0.7\n\n\n4\nNaN\n01M696\nbard high school early college\nHigh School\n565.0\nExceeding Target\nApproaching Target\nMeeting Target\nMeeting Target\nMeeting Target\n...\n2578.0\n16.2\n38.1\n53.0\n13.0\n38.1\n76.1\n43362.0\n34.0\n0.0\n\n\n\n\n5 rows × 555 columns\n\n\n\nGet pre cleaning data types\n\ndf.dtypes.value_counts()\n\nobject     280\nfloat64    275\nName: count, dtype: int64\n\n\nAccording to the Educator Guide, “metrics with fewer than the minimum number of students are not reported and do not contribute to the school’s ratings because of confidentiality considerations and the unreliability of measurements based on small numbers”1. These are shown in the data as values of ‘N&lt;15’ and ‘N&lt;5’. One cannot impute 0 for these values since that would fasely discredit the school. Instead, I changed these values to NA and did not include them when processing. Similarly, values that are ‘&lt;95%’ will be set as their max 95%.\n\ndf = df.replace('N&lt;15', np.nan).infer_objects(copy=False)\ndf = df.replace('N&lt;5', np.nan).infer_objects(copy=False)\n\ndf = df.replace('&gt; 95%', int(0.95)).infer_objects(copy=False)\n\nEvaluate pre cleaning missingness\n\nplt.figure(figsize=(10, 6))\nsns.heatmap(df.isnull(), cbar=True, cmap=\"viridis\")\nplt.title(\"Missing Values Before Cleaning\")\nplt.show()\n\n\n\n\n\n\n\n\nRemove columns:\n\nUnnamed: remove NA columns\nN count / metric rating / metric score / comparison group: only need metric value % columns, these give the same info\npositive responses / percent positive: remove borough and city positive response columns - only need element score for these metrics\nquality review: these metrics are included in the Element score metrics\nRemove granular columns: scores by specific courses, demographics\n\n\nstring_check = \"Unnamed|N count|metric rating|metric score|comparison group|positive responses|percent positive|Quality Review\"\n\n#specific courses\nspecific_courses = \"Chemistry|Earth Science|Algebra|US History|Geometry|Global History|Living Environment|Credits\"\n\n#demographics\ndemographics = 'Asian|White|Native|Black|Hispanic|Male|Female|English Lang|ELL|IEPs|NYSAA'\n\ndf = df.loc[:, ~df.columns.str.contains(string_check, regex=True, case=False)]\ndf = df.loc[:, ~df.columns.str.contains(specific_courses, regex=True, case=False)]\n\ndf= df.loc[:, ~(df.columns.str.contains(demographics, regex=True, case=False) & ~(df.columns.str.contains('percent ', regex=True, case=False)))]\n\nDrop School Type (they are all High Schools) and columns with survey response questions, there are score columns for this\n\ndf = df.drop(columns=['School Type','Rigorous Instruction Rating','Collaborative Teachers Rating','Supportive Environment Rating','Effective School Leadership Rating','Strong Family-Community Ties Rating','Trust Rating','Student Achievement Rating'], axis=1)\n\n\nFeature Engineering\nAverage rates that are 4 and 6 years then drop\n\ndf['Graduation Rate'] = df[['Metric Value - 6-Year Graduation Rate - All Students', 'Metric Value - 4-Year Graduation Rate - All Students']].mean(axis=1)\ndf['% Attaining Regents Diploma'] = df[['Metric Value - % Attaining Regents Diploma (4 year)', 'Metric Value - % Attaining Regents Diploma (6 year)']].mean(axis=1)\ndf['High School Persistence Rate'] = df[['Metric Value - 6-Year High School Persistence Rate', 'Metric Value - 4-Year High School Persistence Rate']].mean(axis=1)\ndf = df.drop(columns=['Metric Value - 6-Year Graduation Rate - All Students',\n                    'Metric Value - 4-Year Graduation Rate - All Students',\n                    'Metric Value - % Attaining Regents Diploma (4 year)',\n                    'Metric Value - % Attaining Regents Diploma (6 year)',\n                    'Metric Value - 4-Year High School Persistence Rate',\n                    'Metric Value - 6-Year High School Persistence Rate'])\n\nCombine student demographic percentages - group black and hispanic since its the majority. Combine teacher demographic percentages - 2 groups: Teacher White and Teacher Other. Remove nearby student percentages. Remove Borough Percentages.\n\n#student demographic \ndf['Student Percent - Black and Hispanic'] = (df['Student Percent - Black'] + df['Student Percent - Hispanic'])\ndf['Student Percent - Other'] = df['Student Percent - Native American'] + df['Student Percent - Native Hawaiian or Pacific Islander'] + df['Student Percent - Asian'] + df['Student Percent - White']\ndf = df.drop(['Student Percent - White','Student Percent - Native American', 'Student Percent - Native Hawaiian or Pacific Islander','Student Percent - Asian', 'Student Percent - Black', 'Student Percent - Hispanic'], axis=1)\n\n#teacher demographic \ndf['Teacher - Other'] = df['Teacher Percent - Native American'] + df['Teacher Percent - Native Hawaiian or Pacific Islander'] + df['Teacher Percent - Asian'] + df['Teacher Percent - Hispanic'] + df['Teacher Percent - Black']\ndf = df.drop(['Teacher Percent - Native American', 'Teacher Percent - Native Hawaiian or Pacific Islander','Teacher Percent - Asian', 'Teacher Percent - Black', 'Teacher Percent - Hispanic'], axis=1)\n\n#nearby student percentages\ndf = df.drop(['Nearby Student Percent - White','Nearby Student Percent - Native American', 'Nearby Student Percent - Native Hawaiian or Pacific Islander','Nearby Student Percent - Asian', 'Nearby Student Percent - Black', 'Nearby Student Percent - Hispanic'], axis=1)\n\n#Borough Percentages\ndf = df.drop(['Borough Percent - White','Borough Percent - Native American', 'Borough Percent - Native Hawaiian or Pacific Islander','Borough Percent - Asian', 'Borough Percent - Black', 'Borough Percent - Hispanic'], axis=1)\n\nOnly keep general postsecondary enrollment and graduation columns\n\ndf = df.loc[:, ~((df.columns.str.contains(\"postsecondary enrollment\", case=False)) & ~(df.columns == \"Metric Value - Postsecondary Enrollment Rate\"))]\ndf= df.loc[:, ~(df.columns.str.contains('graduated|graduation', regex=True, case=False) & ~(df.columns == \"Graduation Rate\"))]\n\nExtract District and Borough from DBN column and map borough name to value\nDBN: (##(District)X(Borough)###(School ID))\n\ndf = df.copy()\ndf['District'] = df['DBN'].str[0:2]\ndf['Borough'] = df['DBN'].str[2:3]\n\nborough_map = {'M': 'Manhattan', 'K': 'Brooklyn', 'X': 'Bronx', 'Q':'Queens', 'R':'Staten Island'}\ndf['Borough'] = df['Borough'].map(borough_map) \n\nCombine ACT metrics and SAT metrics, drop repetitive regents metrics\n\n#ACT \ndf['Percent who took ACT'] = df[['Metric Value - % of cohort who took the ACT English exam','Metric Value - % of cohort who took the ACT Reading exam']].mean(axis=1)\ndf['Percent with 20+ ACT'] = df[['Metric Value - % of students in the current cohort who took the ACT English exam who scored 20+','Metric Value - % of students in the current cohort who took the ACT Math exam who scored 21+']].mean(axis=1)\ndf = df.drop(['Metric Value - % of cohort who took the ACT English exam','Metric Value - % of cohort who took the ACT Reading exam','Metric Value - % of students in the current cohort who took the ACT English exam who scored 20+','Metric Value - % of students in the current cohort who took the ACT Math exam who scored 21+'], axis=1)\n\n#SAT \ndf['Percent College Ready based on SAT Math'] = df['Metric Value - % of students in the current cohort who took the SAT Math exam who passed the college ready threshold']\ndf.drop(['Metric Value - % of students in the current cohort who took the SAT Math exam who passed the college ready threshold','Metric Value - % of students in the current cohort who took the SAT Reading and Writing exam and scored 480+'], axis=1, inplace=True )\n\n#Regents\ndf = df.drop(columns=['Metric Value - % of students who took the English Regents exam and are college ready (scored 70+)','Metric Value - % of students who took the English Regents exam in the current year who scored 65+'])\n\nCombine 8th grade proficiency metrics and drop lowest third citywide metrics since it is based on average grade 8 proficiency\n\ndf['Average Grade 8 Proficiency'] = df[['Average Grade 8 English Proficiency', 'Average Grade 8 Math Proficiency']].mean(axis=1)\ndf.drop(columns =['Average Grade 8 English Proficiency','Average Grade 8 Math Proficiency'],inplace=True)\n\ndf = df.loc[:, ~(df.columns.str.contains('Lowest Third'))]\n\nDrop students recommended for Individualized Education Programs (IEPs)\n\ndf.drop(['Percentage of students recommended for general ed settings with Special Ed Teacher Support Services (SETSS)','Percentage of students recommended for Integrated Co-Teaching (ICT) services','Percentage of students recommended for Special Class (SC) services'], axis=1, inplace=True)\n\nDrop columns that give same info as targets: graduation rate and chronic absenteeism\n\ndf.drop(columns=['High School Persistence Rate','% Attaining Regents Diploma','Metric Value - Percentage of Students with 90%+ Attendance','Average Student Attendance'], inplace=True)\n\nDrop columns that are captured in the College and Career Preparatory Course Index (CCPCI)1.\n\ndf = df.drop(columns=['Metric Value - % Scoring 3+ on any AP Exam',\n       'Metric Value - % Passing a NYCPS-certified CPCC Course',\n       'Metric Value - % Passing an Industry-Recognized Technical Assessment',\n       'Metric Value - % Scoring 4+ on any IB Exam',\n       \"Metric Value - % Earning a Grade of 'C' or Higher for College Credit\",\n       'Metric Value - % Scoring 65+ on Alg2, Chem, or Phys Regents Exam',\n       'Metric Value - % Earning a Diploma with an Arts Endorsement',\n       'Metric Value - % Earning a Diploma with a CTE Endorsement'], axis=1)\n\nMake course columns with low occurence into binary rather than percentages - more interperable. Drop the originals\n\ndf['CLEP_enrolled'] = (df['Percentage of Students Enrolled in a College Level Examination Program (CLEP)'] &gt; 0).astype(float)\ndf['IB_enrolled'] = (df['Percentage of Students Enrolled in an IB Course'] &gt; 0).astype(float)\ndf['NYCPS_college_prep_enrolled'] = (df['Percentage of Students Enrolled in an NYCPS-certified College Preparatory Course'] &gt; 0).astype(float)\ndf['Took_ACT'] = (df['Percent who took ACT'] &gt; 0).astype(float)\n\n\ndf = df.drop(columns=['Percentage of Students Enrolled in a College Level Examination Program (CLEP)',\n                    'Percentage of Students Enrolled in an IB Course',\n                    'Percentage of Students Enrolled in an NYCPS-certified College Preparatory Course',\n                    'Percent who took ACT', 'Percent with 20+ ACT'], axis=1)\n\nHandle Data Types: Converting all columns to numeric is essential for EDA to create plots and for modeling as regression will only take numeric values.\nChange all percent columns to max 1 for uniformity\n\n#convert rate % to float\ndf['Student Survey Response Rate'] = pd.to_numeric(df['Student Survey Response Rate'].str[:-1])\ndf['Teacher Survey Response Rate'] = pd.to_numeric(df['Teacher Survey Response Rate'].str[:-1])\ndf['Parent Survey Response Rate'] = pd.to_numeric(df['Parent Survey Response Rate'].str[:-1])\n\n#convert all metric value columns to numeric\ndf.loc[:, df.columns.str.contains('Metric Value')] = df.loc[:, df.columns.str.contains('Metric Value')].apply(pd.to_numeric, errors='coerce')\n\n\ndf['Metric Value - Average Regents Score - English'] = df['Metric Value - Average Regents Score - English']/100\ndf['Parent Survey Response Rate'] = df['Parent Survey Response Rate']/100\ndf['Teacher Survey Response Rate'] = df['Teacher Survey Response Rate']/100\ndf['Student Survey Response Rate'] = df['Student Survey Response Rate']/100\ndf['Percent Households with Broadband Internet'] = df['Percent Households with Broadband Internet']/100\ndf['Percent Foreign-Born Population'] = df['Percent Foreign-Born Population']/100\ndf['Percent Population with Disabilities'] = df['Percent Population with Disabilities']/100\ndf['Percent Language Other Than English at Home'] = df['Percent Language Other Than English at Home']/100\ndf[\"Percent Bachelor's Degree or Higher (25+)\"] = df[\"Percent Bachelor's Degree or Higher (25+)\"]/100\ndf['Percent No High School (25+)'] = df['Percent No High School (25+)']/100\ndf['Percent Households on SNAP/Food Stamps'] = df['Percent Households on SNAP/Food Stamps']/100\ndf['dropout_rate'] = df['dropout_rate']/100\n\nHandle Missingness: To address the large amounts of missing data, I first removed columns where more than 50% of the data was missing. This step significantly reduced the size of the dataframe by eliminating over 100 columns that wouldn’t have contributed meaningfully to the analysis due to the high volume of missing values. Next, I focused on imputing data for columns with less than 10% missing values. For imputation, I used the skew of the distribution to determine the best method. If the skew was greater than an absolute value of 0.5, I imputed using the median, as this is more robust to outliers. If the distribution appeared to be approximately normal, I used the mean for imputation. Finally, I removed the remaining three columns with missing data that did not meet the threshold, ensuring a complete and clean dataset for analysis.\n\nlen(df.columns)\n\n71\n\n\n\ndef handle_missingness(df, threshold=0.1):\n    \"\"\"Function for imputing data using skew when missingness &lt; 10% and removing columns with missingness &gt; 50% \"\"\"\n    for col in df.columns:\n        missingness = df[col].isna().sum() / len(df)\n        if missingness &lt; 0.1:\n            if df[col].dtype == 'float64':\n                col_skew = skew(df[col].dropna()) \n                if abs(col_skew) &gt; 0.5:\n                    df[col] = df[col].fillna(df[col].median())\n                else: \n                    df[col] = df[col].fillna(df[col].mean())\n            elif df[col].dtype == 'object':\n                df[col] = df[col].fillna(df[col].mode()[0]) \n        elif missingness &gt; 0.5:\n            df.drop([col], axis=1, inplace=True)\n    return df\n\n\ndf = handle_missingness(df)\n\nCheck null count of each column\n\ndf.isnull().sum().sort_values(ascending=False).head(20)\n\nMetric Value - Average score of students in the current cohort who took the SAT Reading and Writing exam    76\nMetric Value - Average score of students in the current cohort who took the SAT Math exam                   76\nStudent Achievement - Section Score                                                                         72\nMetric Value - Average Completion Rate for Remaining Regents                                                52\nPercent Male                                                                                                 0\nPercent Female                                                                                               0\nPercent English Language Learners                                                                            0\nPercent Students with IEPs                                                                                   0\nEconomic Need Index                                                                                          0\nPercent Neither Female nor Male                                                                              0\nDBN                                                                                                          0\nPercent in Temp Housing                                                                                      0\nPercent Overage / Undercredited                                                                              0\nPercent HRA Eligible                                                                                         0\nTeacher Percent - White                                                                                      0\nPercentage of Students Enrolled in an Advanced Math or Science Course                                        0\nPercentage of Students Enrolled in a College Credited Course                                                 0\nNearby Student Distance (mi)                                                                                 0\nPercentage of Students Enrolled in an AP Course                                                              0\nYears of principal experience at this school                                                                 0\ndtype: int64\n\n\nDrop remaining columns with missingness\n\ndf = df.drop(columns=['Metric Value - Average score of students in the current cohort who took the SAT Reading and Writing exam','Metric Value - Average score of students in the current cohort who took the SAT Math exam','Student Achievement - Section Score','Metric Value - Average Completion Rate for Remaining Regents'], axis=1)\n\nPost cleaning data check\n\ndf.dtypes.value_counts()\n\nfloat64    51\nobject      4\nName: count, dtype: int64\n\n\nThe remaining object columns are ‘DBN’, ‘School Name’, ‘District’, and ‘Borough’. These will be kept for EDA purposes.\n\ndf.select_dtypes(include=['object']).columns\n\nIndex(['DBN', 'School Name', 'District', 'Borough'], dtype='object')\n\n\nSave processed df to csv\n\ndf.to_csv('../../data/processed-data/processed_df.csv', index=None)\n\nPost cleaning df.head check\n\ndf.head()\n\n\n\n\n\n\n\n\nDBN\nSchool Name\nEnrollment\nPercent Female\nPercent Male\nPercent Neither Female nor Male\nPercent English Language Learners\nPercent Students with IEPs\nEconomic Need Index\nPercent Overage / Undercredited\n...\nStudent Percent - Black and Hispanic\nStudent Percent - Other\nDistrict\nBorough\nPercent College Ready based on SAT Math\nAverage Grade 8 Proficiency\nCLEP_enrolled\nIB_enrolled\nNYCPS_college_prep_enrolled\nTook_ACT\n\n\n\n\n0\n01M292\norchard collegiate academy\n269.0\n0.468\n0.532\n0.0\n0.063\n0.253\n0.866\n0.041\n...\n0.766\n0.227\n01\nManhattan\n0.136\n2.715\n0.0\n0.0\n0.0\n0.0\n\n\n1\n01M448\nuniversity neighborhood high school\n485.0\n0.487\n0.513\n0.0\n0.118\n0.210\n0.814\n0.029\n...\n0.625\n0.371\n01\nManhattan\n0.225\n3.050\n0.0\n0.0\n0.0\n0.0\n\n\n2\n01M450\neast side community school\n389.0\n0.458\n0.542\n0.0\n0.013\n0.290\n0.638\n0.003\n...\n0.684\n0.283\n01\nManhattan\n0.370\n3.010\n0.0\n0.0\n1.0\n1.0\n\n\n3\n01M539\nnew explorations into science, technology and ...\n620.0\n0.508\n0.492\n0.0\n0.005\n0.185\n0.429\n0.005\n...\n0.249\n0.705\n01\nManhattan\n0.834\n3.755\n0.0\n0.0\n0.0\n1.0\n\n\n4\n01M696\nbard high school early college\n565.0\n0.577\n0.423\n0.0\n0.005\n0.147\n0.482\n0.004\n...\n0.391\n0.570\n01\nManhattan\n0.762\n3.840\n0.0\n0.0\n0.0\n1.0\n\n\n\n\n5 rows × 55 columns\n\n\n\nPost cleaning missingness check\n\nplt.figure(figsize=(10, 6))\nsns.heatmap(df.isnull(), cbar=True, cmap=\"viridis\")\nplt.title(\"Missing Values After Cleaning\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nConclusion\nI chose to work with this specific subset of the data because it retains the key columns I am most interested in exploring. I decided to drop columns that were too granular, such as specific course types and certain demographic data, which were not directly relevant to my analysis. Additionally, some metric columns contained redundant information already captured by the ‘Metric Value’ columns I kept. As a result, I removed the N count, metric rating, metric score, comparison group, and positive response columns. After this filtering process, the dataset is now streamlined, containing 55 columns and 501 rows, ensuring a more focused and manageable analysis.\n\n\n\n\n\nReferences\n\n1. NYC Public Schools InfoHub (2024)."
  },
  {
    "objectID": "technical-details/eda/main.html",
    "href": "technical-details/eda/main.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Exploratory Data Analysis (EDA) is a crucial beginning step in any data science project. On this page, I will examine distributions, analyze correlations, and uncover relationships between variables, ensuring the data is ready for the modeling phase. These insights will guide and shape our modeling approach. It is important to avoid modeling blindly and instead base our decisions on a thorough understanding of the data.\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport textwrap\nimport plotly.express as px\nimport scipy.stats as stats\nfrom scipy.stats import ttest_ind, skew, kurtosis, f_oneway\nimport plotly.io as pio\n#pio.renderers.default = \"notebook\"\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport warnings\nwarnings.filterwarnings('ignore')\nCode\ndf = pd.read_csv('../../data/processed-data/processed_df.csv')"
  },
  {
    "objectID": "technical-details/eda/main.html#univariate-analysis",
    "href": "technical-details/eda/main.html#univariate-analysis",
    "title": "Exploratory Data Analysis",
    "section": "Univariate Analysis",
    "text": "Univariate Analysis\nSummary Statistics\n\n\nCode\ndf.describe().T\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nEnrollment\n501.0\n568.892216\n683.763617\n11.00000\n287.00000\n388.000000\n497.0000\n5942.00000\n\n\nPercent Female\n501.0\n0.488070\n0.143794\n0.00000\n0.43000\n0.486000\n0.5400\n1.00000\n\n\nPercent Male\n501.0\n0.511669\n0.143896\n0.00000\n0.46000\n0.514000\n0.5700\n1.00000\n\n\nPercent Neither Female nor Male\n501.0\n0.000257\n0.000948\n0.00000\n0.00000\n0.000000\n0.0000\n0.00900\n\n\nPercent English Language Learners\n501.0\n0.132874\n0.184345\n0.00000\n0.03900\n0.082000\n0.1430\n0.99400\n\n\nPercent Students with IEPs\n501.0\n0.209673\n0.080834\n0.00000\n0.16500\n0.208000\n0.2630\n0.62900\n\n\nEconomic Need Index\n501.0\n0.730691\n0.237780\n0.00000\n0.69000\n0.813000\n0.8810\n0.94900\n\n\nPercent Overage / Undercredited\n501.0\n0.054353\n0.054019\n0.00000\n0.01800\n0.041000\n0.0690\n0.30800\n\n\nPercent in Temp Housing\n501.0\n0.130513\n0.079141\n0.00600\n0.08100\n0.119000\n0.1650\n0.56000\n\n\nPercent HRA Eligible\n501.0\n0.700184\n0.153327\n0.00000\n0.64200\n0.737000\n0.8120\n0.94700\n\n\nTeacher Percent - White\n501.0\n0.430554\n0.161836\n0.00000\n0.32000\n0.430554\n0.5350\n0.85500\n\n\nNearby Student Distance (mi)\n501.0\n2.317565\n1.778227\n0.40000\n1.10000\n1.700000\n2.9000\n9.50000\n\n\nPercentage of Students Enrolled in an AP Course\n501.0\n0.291362\n0.200515\n0.00000\n0.17100\n0.255500\n0.3840\n0.99100\n\n\nPercentage of Students Enrolled in an Advanced Math or Science Course\n501.0\n0.379705\n0.144616\n0.00000\n0.28200\n0.379705\n0.4840\n0.80000\n\n\nPercentage of Students Enrolled in a College Credited Course\n501.0\n0.081681\n0.137217\n0.00000\n0.00000\n0.021000\n0.1150\n0.92300\n\n\nPercentage of Students Enrolled in Any Advanced Course\n501.0\n0.571937\n0.175886\n0.01000\n0.45600\n0.571937\n0.6800\n0.99800\n\n\nYears of principal experience at this school\n501.0\n6.889421\n5.110596\n0.00000\n2.20000\n6.100000\n10.2000\n22.10000\n\n\nPercent of teachers with 3 or more years of experience\n501.0\n0.795406\n0.133245\n0.08000\n0.73700\n0.821500\n0.8820\n1.00000\n\n\nPercent of Students Chronically Absent\n501.0\n0.417344\n0.161082\n0.00000\n0.29900\n0.417344\n0.5320\n0.99800\n\n\nTeacher Attendance Rate\n501.0\n0.952104\n0.027447\n0.65000\n0.95000\n0.957000\n0.9630\n0.99100\n\n\nMetric Value - Average Regents Score - English\n501.0\n0.006958\n0.000932\n0.00291\n0.00639\n0.006958\n0.0075\n0.00956\n\n\nMetric Value - College and Career Preparatory Course Index\n501.0\n0.656958\n0.239731\n0.00700\n0.48700\n0.667000\n0.8750\n1.00000\n\n\nMetric Value - College Persistence\n501.0\n0.485317\n0.186830\n0.02300\n0.34900\n0.481000\n0.6100\n0.97800\n\n\nRigorous Instruction - Element Score\n501.0\n3.473640\n0.651435\n1.80000\n3.03000\n3.473640\n3.8900\n4.97000\n\n\nCollaborative Teachers - Element Score\n501.0\n3.612056\n0.583369\n1.52000\n3.27000\n3.612056\n3.9800\n4.93000\n\n\nSupportive Environment - Element Score\n501.0\n3.577099\n0.417602\n2.02000\n3.32000\n3.577099\n3.8600\n4.65000\n\n\nEffective School Leadership - Element Score\n501.0\n3.552355\n0.570646\n1.28000\n3.27000\n3.560000\n3.8900\n4.86000\n\n\nStrong Family-Community Ties - Element Score\n501.0\n3.442936\n0.612733\n1.38000\n3.10000\n3.442936\n3.8400\n4.83000\n\n\nTrust - Element Score\n501.0\n3.392435\n0.600361\n1.11000\n3.05000\n3.450000\n3.7900\n4.93000\n\n\nStudent Survey Response Rate\n501.0\n0.668503\n0.228916\n0.00000\n0.58000\n0.710000\n0.8300\n1.00000\n\n\nTeacher Survey Response Rate\n501.0\n0.809321\n0.174717\n0.18000\n0.72000\n0.840000\n0.9500\n1.00000\n\n\nParent Survey Response Rate\n501.0\n0.340699\n0.230840\n0.00000\n0.16000\n0.290000\n0.4800\n0.96000\n\n\nzip code\n501.0\n10715.345309\n535.154739\n10002.00000\n10302.00000\n10468.000000\n11217.0000\n11694.00000\n\n\nPercent No High School (25+)\n501.0\n0.092210\n0.053057\n0.00000\n0.05200\n0.084000\n0.1300\n0.25900\n\n\nPercent Bachelor's Degree or Higher (25+)\n501.0\n0.394619\n0.222599\n0.11600\n0.21600\n0.339000\n0.5180\n0.94500\n\n\nPercent Language Other Than English at Home\n501.0\n0.465610\n0.185487\n0.14000\n0.31100\n0.500000\n0.6020\n0.86300\n\n\nPercent Population with Disabilities\n501.0\n0.122088\n0.040745\n0.01600\n0.09000\n0.117000\n0.1510\n0.21300\n\n\nPercent Foreign-Born Population\n501.0\n0.339353\n0.114667\n0.13700\n0.25400\n0.316000\n0.4030\n0.70900\n\n\nPercent Households with Broadband Internet\n501.0\n0.864076\n0.054931\n0.71100\n0.82400\n0.875000\n0.8960\n0.99400\n\n\nMedian Household Income\n501.0\n78499.157685\n41488.175277\n26400.00000\n43985.00000\n67489.000000\n100190.0000\n250001.00000\n\n\nPercent Households on SNAP/Food Stamps\n501.0\n0.238082\n0.142630\n0.00000\n0.11700\n0.216000\n0.3400\n0.52000\n\n\ndropout_rate\n501.0\n0.053580\n0.052614\n0.00000\n0.01225\n0.037000\n0.0770\n0.27650\n\n\nGraduation Rate\n501.0\n0.899607\n0.072814\n0.57950\n0.85300\n0.908750\n0.9595\n1.00000\n\n\nStudent Percent - Black and Hispanic\n501.0\n0.799110\n0.213992\n0.04500\n0.72900\n0.891000\n0.9490\n1.00000\n\n\nStudent Percent - Other\n501.0\n0.183108\n0.206603\n0.00000\n0.04100\n0.094000\n0.2520\n0.94700\n\n\nDistrict\n501.0\n25.339321\n27.018524\n1.00000\n8.00000\n16.000000\n28.0000\n84.00000\n\n\nPercent College Ready based on SAT Math\n501.0\n0.152992\n0.213768\n0.00000\n0.02300\n0.075000\n0.1900\n1.00000\n\n\nAverage Grade 8 Proficiency\n501.0\n2.753443\n0.436318\n1.75500\n2.47500\n2.680000\n2.9550\n4.27000\n\n\nCLEP_enrolled\n501.0\n0.017964\n0.132954\n0.00000\n0.00000\n0.000000\n0.0000\n1.00000\n\n\nIB_enrolled\n501.0\n0.039920\n0.195967\n0.00000\n0.00000\n0.000000\n0.0000\n1.00000\n\n\nNYCPS_college_prep_enrolled\n501.0\n0.083832\n0.277413\n0.00000\n0.00000\n0.000000\n0.0000\n1.00000\n\n\nTook_ACT\n501.0\n0.223553\n0.417042\n0.00000\n0.00000\n0.000000\n0.0000\n1.00000\n\n\n\n\n\n\n\n\nTransformations\nView distribution of numerical features with histogram\n\n\nCode\nnumerical_columns = df.select_dtypes(include=['float64']).columns\n\naxes = df[numerical_columns].hist(figsize=(30, 30))\nplt.tight_layout()\n\n# wrap the titles for readability\nfor ax, col in zip(axes.flatten(), numerical_columns):\n    wrapped_title = textwrap.fill(col, width=30)\n    ax.set_title(wrapped_title)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nBased on these distributions, it may be necessary to transform some variables before modeling. Lets check the actual skews:\n\n\nCode\nskewness = df.apply(lambda col: skew(col) if col.dtype != 'object' else None)\n\n\n\n\nCode\nskewness.loc[abs(skewness) &gt; 1]\n\n\nEnrollment                                                      3.738744\nPercent Neither Female nor Male                                 5.155183\nPercent English Language Learners                               3.151075\nEconomic Need Index                                            -1.952382\nPercent Overage / Undercredited                                 2.173497\nPercent in Temp Housing                                         1.785170\nPercent HRA Eligible                                           -1.271196\nNearby Student Distance (mi)                                    1.538479\nPercentage of Students Enrolled in a College Credited Course    2.898833\nPercent of teachers with 3 or more years of experience         -1.445006\nTeacher Attendance Rate                                        -5.282616\nStudent Survey Response Rate                                   -1.222827\nTeacher Survey Response Rate                                   -1.131656\nMedian Household Income                                         1.219752\ndropout_rate                                                    1.395944\nStudent Percent - Black and Hispanic                           -1.511319\nStudent Percent - Other                                         1.560287\nDistrict                                                        1.464517\nPercent College Ready based on SAT Math                         2.235895\nCLEP_enrolled                                                   7.258441\nIB_enrolled                                                     4.700168\nNYCPS_college_prep_enrolled                                     3.003344\nTook_ACT                                                        1.327076\ndtype: float64\n\n\nI will take the log of some variables of interest exhibiting the power law\n\n\nCode\ndf_transformed = df.copy()\n\ndf_transformed['log_dropout_rate'] = np.log(df_transformed['dropout_rate'] + 1)\ndf_transformed['log_temp_housing'] = np.log(df_transformed['Percent in Temp Housing'] + 1)\ndf_transformed['log_percent_overage'] = np.log(df_transformed['Percent Overage / Undercredited'] + 1)\ndf_transformed['log_enrollment'] = np.log(df_transformed['Enrollment'] + 1)\ndf_transformed['log_nearby_student_distance'] = np.log(df_transformed['Nearby Student Distance (mi)'] + 1)\ndf_transformed['log_household_income'] = np.log(df_transformed['Median Household Income'] + 1)\n\n\n\n\nCode\nnumerical_columns = df_transformed.select_dtypes(include=['float64']).columns\n\naxes = df_transformed[numerical_columns].hist(figsize=(30, 30))\nplt.tight_layout()\n\n# wrap the titles for readability\nfor ax, col in zip(axes.flatten(), numerical_columns):\n    wrapped_title = textwrap.fill(col, width=30)\n    ax.set_title(wrapped_title)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nThe distribution of drop out rate, temp housing, nearby student distance, enrollment, and household income seem more normally distributed now. I will drop the original columns and save this dataframe for later use in regression analysis.\n\n\nCode\ndf_transformed.drop(columns=['dropout_rate','Percent in Temp Housing','Enrollment','Nearby Student Distance (mi)','Median Household Income','Percent Overage / Undercredited'], axis=1, inplace=True)\ndf_transformed.to_csv('../../data/processed-data/transformed_df.csv')\n\n\n\n\nMultivariate Analysis\nVisualize correlations with heatmap of all numeric columns from original dataset\n\n\nCode\nnumeric_columns = df.select_dtypes(include=['float64'])\ncorr = numeric_columns.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nf, ax = plt.subplots(figsize=(20, 20))  \nsns.heatmap(corr, mask=mask, cmap='vlag', vmin=-1, vmax=1, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nplt.show()\n\n\n\n\n\n\n\n\n\nIt looks like there are some high correlations, specifically some data that is perfectly multicollinear. For example ‘Percent Female’ and ‘Percent Male’ is nearly perfectly negatively correlated and ‘Student Percent - Black and Hispanic’ and ‘Student Percent - Other’ is perfectly negatively correlated since there are only two population groups.This will have to be removed for modeling."
  },
  {
    "objectID": "technical-details/eda/main.html#statistical-testing",
    "href": "technical-details/eda/main.html#statistical-testing",
    "title": "Exploratory Data Analysis",
    "section": "Statistical Testing",
    "text": "Statistical Testing\nLets try to uncover relationships between some of our target variables and features in the data\n\nT-test\nI will use a t test to evaluate if there is difference in the means of two groups\n\nDropout Rate vs Median Household Income\nFirst, I want to see if there is a relationship between median household income and dropout rate. Looking at the graph, it appears that high median income is associated with low dropout rates. I will do a t-test to validate this assumption.\n\n\nCode\nsns.regplot(data=df, y='dropout_rate', x='Median Household Income', scatter_kws={'edgecolor': 'black'}, color='green')\nplt.title('Median Household Income vs Dropout Rate')\nplt.ylabel('Dropout Rate')\nplt.xlabel('Median Household Income')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nhigh_dropout = df[df['dropout_rate'] &gt; .077]['Median Household Income']\nlow_dropout = df[df['dropout_rate'] &lt;= .077]['Median Household Income']\n\nt_stat, p_value = ttest_ind(high_dropout, low_dropout)\nprint(f't-value = {t_stat:.2f}, p-value = {p_value:.3f}')\n\n\nt-value = -2.79, p-value = 0.006\n\n\n\nNull Hypothesis: There is no difference in mean median household income between schools with high dropout and low dropout rates.\nAlternative Hypothesis: There is a difference in mean median household income between schools with high and low droppout rates\nConclusion: The p-value is 0.006, allowing us to reject the null hypothesis and conclude that there is significant difference in the mean median household income of schools with high dropout rates vs low dropout rates.\n\n\n\nChronic Absenteeism vs Supportive School Environment\nNow I want to check the relationship between chronic absenteeism and a supportive school environment.\n\n\nCode\nsns.regplot(data=df, x='Percent of Students Chronically Absent', y='Supportive Environment - Element Score', scatter_kws={'edgecolor': 'black'}, color='purple')\nplt.title('Chronic Absenteeism vs School Support')\nplt.xlabel('Percent of Students Chronically Absent')\nplt.ylabel('Supportive Environment Score')\nplt.show()\n\n\n\n\n\n\n\n\n\nIt appears that lower supportive environment scores is associated with high rates of chronic absenteeism. A t-test can be done to validate the assumption that there is a difference in supportive score for schools with high and low chronic absenteeism\n\n\nCode\nhigh_chronic_absent = df[df['Percent of Students Chronically Absent'] &gt; .4]['Supportive Environment - Element Score']\nlow_chronic_absent = df[df['Percent of Students Chronically Absent'] &lt;= .4]['Supportive Environment - Element Score']\n\nt_stat, p_value = ttest_ind(high_chronic_absent, low_chronic_absent)\nprint(f't-value = {t_stat:.2f}, p-value = {p_value:.3f}')\n\n\nt-value = -11.44, p-value = 0.000\n\n\n\nNull Hypothesis: There is no difference in mean supportive environment score between schools with high chronic absenteeism and low chronic absenteeism.\nAlternative Hypothesis: There is a difference in mean supportive environment score between schools with high chronic absenteeism and low chronic absenteeism.\nConclusion: The p-value is less than 0.05, allowing us to reject the null hypothesis and conclude that there is significant difference in the mean supportive environment element score of schools with high chronic absenteeism vs low chronic absenteeism.\n\n\n\n\nANOVA\nAn ANOVA test is used to evaluate if there is a difference in the means of more than two groups\n\n\nEconomic Need Index vs College Persistence Rates\nThe Economic Need Index estimates the percentage of the students at the school facing economic hardship.1 As shown by the box plot, it looks like low rates of college persistence is associated with high Economic Need Index. I will use an ANOVA test to see if there is a statistical difference in Economic Need Index between these three groups of persistence rates.\n\n\nCode\ndf['college_persistence_ranking'] = pd.cut(df['Metric Value - College Persistence'], bins=3, labels=['Low','Medium','High'])\n\n\n\n\nCode\nsns.boxplot(data=df, x='college_persistence_ranking', y='Economic Need Index',color='lightblue')\nplt.title('Economic Need Index vs College Persistence Rates')\nplt.xlabel('College Persistence Rates')\nplt.ylabel('Economic Need Index')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nanova_result = f_oneway(\n    df[df['college_persistence_ranking']=='Low']['Economic Need Index'],\n    df[df['college_persistence_ranking']=='Medium']['Economic Need Index'],\n    df[df['college_persistence_ranking']=='High']['Economic Need Index']\n)\nprint(f'F value = {anova_result.statistic:.2f}, p-value = {anova_result.pvalue:.3f}')\n\n\nF value = 21.57, p-value = 0.000\n\n\n\nNull Hypothesis: There is no difference in mean economic need index between schools with high, medium, and low college persistence rates.\nAlternative Hypothesis: There is a difference in mean economic need index between schools with high, medium, and low college persistence rates.\nConclusion: The p-value less than 0.05, allowing us to reject the null hypothesis and conclude that there is significant difference in the mean economic need index between at least one of the college persistence ranking groups (High, Medium, Low)."
  },
  {
    "objectID": "technical-details/eda/main.html#additional-visualizations",
    "href": "technical-details/eda/main.html#additional-visualizations",
    "title": "Exploratory Data Analysis",
    "section": "Additional Visualizations",
    "text": "Additional Visualizations\nTaking a look at a box plot of dropout rates by borough, it is apparent that the Bronx has the highest rates of dropout. In addition, the median for Queens is low but there are some high outliers.\n\n\nCode\ncolors = ['#1E90FF','#FF6347','#FFD700','#D2B48C', '#98FB98']\nsns.boxplot(x='Borough', y='dropout_rate', data=df, palette=colors)\nplt.title('Dropout Rate by Borough')\nplt.ylabel('Dropout Rate')\nplt.show()\n\n\n\n\n\n\n\n\n\nLooking at chronic absenteeism and dropout rates by district, certain districts clearly have higher medians and IQRs, especially some high spread and outliers in district 84 for chronic abseentism, and a high drop out rate in district 12.\n\n\nCode\nplt.figure(figsize=(14, 6))\nsns.boxplot(data=df, x='District', y='Percent of Students Chronically Absent')\nplt.title('Percent of Chronic Absenteeism by District')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure(figsize=(14, 6))\nsns.boxplot(data=df, x='District', y='dropout_rate')\nplt.title('Dropout Rate by District')\nplt.ylabel('Dropout Rate')\nplt.show()\n\n\n\n\n\n\n\n\n\nIt appears that high college persistence is associated with high average grade 8 proficiency. This emphasizes the importance of early intervention.\n\n\nCode\nplt.scatter(data=df, x='Metric Value - College Persistence', y='Average Grade 8 Proficiency', edgecolors='black')\nplt.title('College Persistence vs Average Grade 8 Proficiency')\nplt.xlabel('College Persistence')\nplt.ylabel('Average Grade 8 Proficiency')\nplt.show()\n\n\n\n\n\n\n\n\n\nLets take a look at how all three of our target metrics work together in this interactive plot\n\n\nCode\nfig = px.scatter(df, x='Percent of Students Chronically Absent', y='dropout_rate', color='Metric Value - College Persistence')\nfig.update_layout(title='Percent of Student Chronically Absent vs Dropout Rate', xaxis_title='Percent of Students Chronically Absent', yaxis_title='Dropout Rate')\nfig.show()\n\n\n                                                \n\n\nIt looks like high rates of college persistence are associated with low dropout rates and low percentages of student chronically absent - a motivating example of why intervention is needed to reduce these two metrics in order to maximize college persistence!"
  },
  {
    "objectID": "technical-details/eda/main.html#feature-selection",
    "href": "technical-details/eda/main.html#feature-selection",
    "title": "Exploratory Data Analysis",
    "section": "Feature Selection",
    "text": "Feature Selection\nFor further analysis, feature selection will done to help us prepare for modeling\nLets check what columns are most correlated with our regression target, from our transformed data\n\n\nCode\nnumeric_columns = df_transformed.select_dtypes(include=['float64'])\n\ntarget_column = 'Percent of Students Chronically Absent'\n\ncorrelations = numeric_columns.corr()[target_column].sort_values(ascending=False)\n\npositive_correlations = correlations[correlations &gt; 0]\nnegative_correlations = correlations[correlations &lt; 0]\n\nprint(positive_correlations.head(10).sort_values(ascending=False))\nprint(negative_correlations.sort_values(ascending=True).head(15)) \n\n\nPercent of Students Chronically Absent    1.000000\nPercent HRA Eligible                      0.476284\nStudent Percent - Black and Hispanic      0.434400\nlog_dropout_rate                          0.386007\nPercent Students with IEPs                0.383127\nlog_temp_housing                          0.331457\nlog_percent_overage                       0.323949\nEconomic Need Index                       0.215888\nPercent English Language Learners         0.110565\nTeacher Survey Response Rate              0.102258\nName: Percent of Students Chronically Absent, dtype: float64\nAverage Grade 8 Proficiency                                    -0.558927\nPercent College Ready based on SAT Math                        -0.554737\nMetric Value - College Persistence                             -0.526158\nSupportive Environment - Element Score                         -0.507653\nGraduation Rate                                                -0.477225\nStudent Percent - Other                                        -0.441859\nMetric Value - Average Regents Score - English                 -0.422453\nMetric Value - College and Career Preparatory Course Index     -0.418735\nTook_ACT                                                       -0.347957\nRigorous Instruction - Element Score                           -0.324224\nPercentage of Students Enrolled in Any Advanced Course         -0.291525\nlog_enrollment                                                 -0.276258\nPercentage of Students Enrolled in an AP Course                -0.202747\nPercentage of Students Enrolled in a College Credited Course   -0.174936\nCollaborative Teachers - Element Score                         -0.167373\nName: Percent of Students Chronically Absent, dtype: float64\n\n\n\n\nCode\nfeatures = df_transformed[[ \"Percent of Students Chronically Absent\",\n    \"Percent HRA Eligible\",\n    \"Student Percent - Black and Hispanic\",\n    \"Percent Students with IEPs\",\n    \"log_dropout_rate\",\n    \"log_temp_housing\",\n    \"log_percent_overage\",\n    \"Economic Need Index\",\n    \"Percent English Language Learners\",\n    \"Average Grade 8 Proficiency\",\n    \"Percent College Ready based on SAT Math\",\n    \"Metric Value - College Persistence\",\n    \"Supportive Environment - Element Score\",\n    \"Graduation Rate\",\n    \"Metric Value - Average Regents Score - English\",\n    \"Metric Value - College and Career Preparatory Course Index\",\n    \"Took_ACT\", 'Rigorous Instruction - Element Score','Percentage of Students Enrolled in Any Advanced Course','log_enrollment']]\n\n\nNow I have a dataset of 20 features.\nOne can visualize these correlations using pairplot, making sure there are no zero looking correlations, or something that looks like a big blob of dots with no apparent relationship\n\n\nCode\nsns.pairplot(features)\n\n\n\n\n\n\n\n\n\nNow I will check the pairwise correlations to ensure that there are no variables that are too correlated to each other\n\n\nCode\ncorr = features.corr()\nf, ax = plt.subplots(figsize=(20, 20))  \nmask = np.triu(np.ones_like(corr, dtype=bool))\nsns.heatmap(corr,  mask=mask, cmap='vlag', annot=True, vmin=-1, vmax=1, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nplt.show()\n\n\n\n\n\n\n\n\n\nThere appears to be relationships with our target and all the features we have included, plus not too high correlations (nothing greater than |0.85|) between the features. Lets export this dataframe for our regression models.\n\n\nCode\nfeatures.to_csv('../../data/processed-data/df_subset_regression.csv', index=False)\n\n\n\nConclusion\nThe EDA process has provided us with valuable insights into the data, which will guide and shape the modeling process. By examining distributions, correlations, and relationships between variables, potential issues have been identified such as skewness and multicollinearity, which help identify transformations and feature engineering necessary. For example, I applied log transformations to variables exhibiting power law distributions, resulted in more normally distributed data, a key assumption for regression analysis.\nI also identified significant relationships between several variables and our target metrics. T-tests showed significant differences in median household income between schools with high and low dropout rates, as well as significant differences in supportive school environment scores between schools with high and low chronic absenteeism. Similarly, the ANOVA test revealed that the there is a significant difference in Economic Need Index for schools with different levels of college persistence. These findings all highlighting the importance of addressing socioeconomic and school quality factors to improve student outcomes.\nGeographic analysis further identified areas where intervention may be necessary, such as high dropout rates in the Bronx and high chronic absenteeism in district 84.\n\n\nNext Steps\n\nData Preprocessing for Modeling: Apply transformations and drop multicollinear features that were identified using correlation heatmap.\nModeling: Develop regression models to predict chronic absenteeism and classification models to identify schools with high dropout rate and low college persistence rates.\nInvestigate additional transformations or feature engineering that can improve model performance.\n\nThese findings highlight the necessity to design targeted interventions in districts with high dropout rates or chronic absenteeism, focusing on socioeconomic factors and school environment. The goal is to build predictive models that can help inform these interventions to improve high school outcomes in New York City."
  },
  {
    "objectID": "technical-details/unsupervised-learning/main.html",
    "href": "technical-details/unsupervised-learning/main.html",
    "title": "Unsupervised Learning",
    "section": "",
    "text": "Unsupervised learning is a branch of machine learning that works with data that does not have predefined labels. The goal is to identify underlying patterns or clusters, but since there are no explicit labels, the algorithm must discover these on its own. Two key components of unsupervised learning are dimensionality reduction and clustering, these are effective methods for reducing high-dimensional data. In this case, I will apply these algorithms to our data to identify relationships between different features and reduce the complexity of the data, with the goal of creating a parsimonious model."
  },
  {
    "objectID": "technical-details/unsupervised-learning/main.html#part-1-dimensionality-reduction",
    "href": "technical-details/unsupervised-learning/main.html#part-1-dimensionality-reduction",
    "title": "Unsupervised Learning",
    "section": "Part 1: Dimensionality Reduction",
    "text": "Part 1: Dimensionality Reduction\n\nPCA\nPrincipal Component Analysis (PCA) is an unsupervised learning technique used for dimensionality reduction. It applies linear transformations to find the most important features, or principal components. It is a great technique to use if you have many dimensions and need a way to visualize them in 2 dimensions. It is also a good preprocessing technique to apple before supervised learning algorithms. The goal of PCA is to capture as much of the variance contained in the data as possible but in reduced dimensions. An important hyperparameter to tune is n_components, which specifies how many prinicipal components you want to retain.\nIn this case, we will apply PCA to our socioeconomic features to explore potential patterns and reduce the dimensionality of the data.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, SpectralClustering\nfrom sklearn.metrics import silhouette_score\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\n\n\n\nCode\ndf = pd.read_csv('../../data/processed-data/processed_df.csv', index_col=None)\n\n\nI will specify a subset of the socioeconomic factors in our dataframe\n\n\nCode\necon_subset = df[[\"Percent HRA Eligible\",\n    \"Percent in Temp Housing\",\n    \"Percent Overage / Undercredited\",\n    \"Economic Need Index\",\n    'Percent No High School (25+)',\n    \"Percent Bachelor's Degree or Higher (25+)\",\n    'Percent Language Other Than English at Home',\n    'Percent Population with Disabilities',\n    'Percent Foreign-Born Population',\n    'Percent Households with Broadband Internet',\n    'Median Household Income',\n    'Percent Households on SNAP/Food Stamps', 'dropout_rate','Percent of Students Chronically Absent','Metric Value - College Persistence']]\n\n\n\n\nCode\ndf_clean = df.drop(columns=['DBN','zip code','School Name','Borough'],axis=1)\n\n\nPCA is sensitive to variance in features of the dataset, so it is necessary to make sure that all our features are on the same scale. This can be achieved using sklean StandardScaler. In addition, it is also necessary to take the log of dropout rate so that it is normally distributed.\n\n\nCode\ndropout_rate = np.log(econ_subset['dropout_rate']+1) \n\nX_features = econ_subset.drop(columns=['Percent of Students Chronically Absent','dropout_rate','Metric Value - College Persistence'], axis=1)\n\n# Scale the features\nX_scaled = scaler.fit_transform(X_features)\n\n\nNow we can fit our PCA and visualize the first two components\n\n\nCode\npca = PCA(n_components=10) \nX_pca = pca.fit_transform(X_scaled)\n\nplt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\nplt.xlabel(\"number of components\")\nplt.ylabel(\"cumulative explained variance\")\nplt.show()\n\n#visualize the first two components\nplt.scatter(X_pca[:,0], X_pca[:,1], c=dropout_rate, cmap='viridis', alpha=0.7)\nplt.xlabel('PC-1')\nplt.ylabel('PC-2')\nplt.title('Principal Component Analysis')\nplt.colorbar(label='Dropout Rate')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npca = PCA(n_components=3) \nX_pca = pca.fit_transform(X_scaled)\n\n\nResults: From the first plot, it is possible to visualize the optimal number of components by examining the cumulative variance explained by additional components. According to this graph, three components appear to be the optimal amount, as the additional variance explained diminishes after that point. The first two components account for about 70% of the variance. Although distinct clusters are not evident from the first two principal components, it can be observed that schools with higher dropout rates tend to be positioned toward the top of the plot, while schools with lower dropout rates are located toward the bottom. This suggests a relationship between the principal components and dropout rates, even if the clusters are not clearly defined. This may indicate a need to use a non-linear algorithm to uncover better relationships in the data. Next, t-SNE can be used to determine if more distinct relationships emerge.\n\n\nt-SNE\nt-distributed Stochastic Neighbor Embedding (t-SNE) is an unsupervised learning technique used for dimensionality reduction. It is effective for high-dimensional data and is preferred over linear methods like PCA when the data has non-linear relationships. It is a great tool for visualizing high dimensional data in 2D. The important hyperparameter here is perplexity, which controls the balance between local and global structure. At a high preplexity, t-SNE preseves global structure and results in more generalized clusters, while a lower perplexity emphasizes local structure and may be able to identify smaller distinct patterns.\nIn this analysis, t-SNE will be applied to the entire dataset to explore how its clustering behavior can help visualize and understand the relationship between school and socioeconomic characteristics and college persistence.\n\n\nCode\n#specify target to color graph by\ncollege_persistence = df_clean['Metric Value - College Persistence']\n\n# drop target column\nX_features = df_clean.drop(['Metric Value - College Persistence'], axis=1)\n\n# scale\nX_scaled = scaler.fit_transform(df_clean)\n\n\n\n\nCode\ntsne = TSNE(n_components=2, perplexity=5)\nX_tsne = tsne.fit_transform(X_scaled)\n\nplt.scatter(X_tsne[:,0], X_tsne[:,1], c=college_persistence, cmap='viridis', alpha=0.7)\nplt.xlabel('t-SNE 1')\nplt.ylabel('t-SNE 2')\nplt.title('t-SNE results')\nplt.colorbar(label='College Persistence')\nplt.show()\n\n\n\n\n\n\n\n\n\nWe can also try a higher perplexity value, which focuses more on global structure rather than local structure\n\n\nCode\ntsne = TSNE(n_components=2, perplexity=50)\nX_tsne = tsne.fit_transform(X_scaled)\n\nplt.scatter(X_tsne[:,0], X_tsne[:,1], c=college_persistence, cmap='viridis', alpha=0.7)\nplt.xlabel('t-SNE 1')\nplt.ylabel('t-SNE 2')\nplt.title('t-SNE results')\nplt.colorbar(label='College Persistence')\nplt.show()\n\n\n\n\n\n\n\n\n\nResults: Although clearly defined and separable clusters are not present, at a low perplexity, one can observe some distinct groupings of schools represented by lighter green and yellow dots, indicating that these schools have high college persistence. Conversely, darker purple clusters represent schools with lower college persistence. In the second graph, where the perplexity is set to 50, the clusters are less clearly separable. However, a noticeable pattern emerges, with high college persistence schools appearing towards the bottom and those with lower college persistence positioned towards the top. From this, one can conclude that t-SNE is able to uncover certain patterns in the data, helping to differentiate schools with varying levels of college persistence, even if the clusters are not perfectly defined.\n\nPCA vs. t-SNE\nBoth of these dimensionality reduction techniques are useful for reducing and visualizing high dimensional data. PCA is preferred for data with linear relationships because it is able to capture the maximum variance through few principal components. On the other hand, t-SNE is better for visualizing non-linear relationships. Depending on the perplexity, t-SNE may preserve local structure at low values and be able to uncover small clusters and relationships. However, this can be tricky if you are interested in interpretting it at the global level. In this case, using t-SNE with a low perplexity successfully grouped schools with similar outcomes, uncovering relationships that were less apparent in both PCA and t-SNE with higher perplexity. Given the small dataset, it appears that t-SNE was able to detect meaningful patterns where larger clusters were not present, revealing some of the underlying relationships between the schools.\n\n\n\nK-means Clustering\nK-means is an unsupervised learning technique used for clustering. The goal is to group data points into distinct clusters. It does this by assigning each point to the nearest cluster center with the goal of minimizing the within-cluster variance.\nTo determine the optimal number of clusters, one can use the elbow method. The elbow method involved plotting the inertia and looking for the “elbow” of the graph, where the reduction in intertia starts to slow down. This is an important way to choose an optimal number of clusters becasue after this point, there is diminishing returns in reducing intertia and adding more clusters.\nThe goal of K-means clustering is: 1. Maximize inter-cluster distance: distance between clusters, high distance means high separation 2. Minimize intra-cluster distance: distance of points in cluster to the center, low distance means high cohesion.\nClusters can be evaluated with a silhouette score. A higher score indicates more well defined clusters.\nK-means clustering will be performed on our data of socioeconomic factors that was reduced with PCA.\n\n\nCode\ninertia = []\nk_values = range(1, 30)\n\nfor k in k_values:\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(X_pca)\n    inertia.append(kmeans.inertia_)\n\nplt.plot(k_values, inertia, marker='o')\nplt.xlabel(\"Number of Clusters (K)\")\nplt.ylabel(\"Inertia\")\nplt.title(\"Elbow Method to Choose K\")\nplt.xticks(k_values)\nplt.show()\n\n\n\n\n\n\n\n\n\nWe can see that the optimal number of clusters is about 4.\n\n\nCode\nn_clusters = 4\nkmeans = KMeans(n_clusters=n_clusters)\necon_clusters = kmeans.fit_predict(X_pca)\n\nfor cluster in range(n_clusters):\n    plt.scatter(X_pca[econ_clusters == cluster, 0], X_pca[econ_clusters == cluster, 1],\n        label=f\"Cluster {cluster + 1}\", s=50, alpha=0.6)\n\nplt.xlabel(\"PCA 1\")\nplt.ylabel(\"PCA 2\")\nplt.title(\"K-means Clustering of Socioeconomic Factors\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nK-means cluster labels can be used to view the means of each variable in the clusters and gauge the clustering performance\n\n\nCode\necon_df = econ_subset.copy()\necon_df['Cluster'] = kmeans.labels_\n\nclusters = econ_df.groupby('Cluster').mean()\nclusters.round(2)\n\n\n\n\n\n\n\n\n\nPercent HRA Eligible\nPercent in Temp Housing\nPercent Overage / Undercredited\nEconomic Need Index\nPercent No High School (25+)\nPercent Bachelor's Degree or Higher (25+)\nPercent Language Other Than English at Home\nPercent Population with Disabilities\nPercent Foreign-Born Population\nPercent Households with Broadband Internet\nMedian Household Income\nPercent Households on SNAP/Food Stamps\ndropout_rate\nPercent of Students Chronically Absent\nMetric Value - College Persistence\n\n\nCluster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n0.81\n0.18\n0.07\n0.75\n0.15\n0.21\n0.60\n0.16\n0.34\n0.81\n41433.45\n0.40\n0.07\n0.44\n0.41\n\n\n1\n0.56\n0.07\n0.03\n0.64\n0.10\n0.39\n0.58\n0.11\n0.46\n0.88\n76731.99\n0.19\n0.03\n0.32\n0.64\n\n\n2\n0.62\n0.11\n0.05\n0.69\n0.02\n0.78\n0.25\n0.08\n0.23\n0.94\n154196.88\n0.06\n0.04\n0.43\n0.54\n\n\n3\n0.73\n0.13\n0.06\n0.80\n0.07\n0.38\n0.36\n0.11\n0.32\n0.87\n77204.32\n0.20\n0.06\n0.45\n0.43\n\n\n\n\n\n\n\n\n\nCode\nprint(f'Silhouette Score: {silhouette_score(X_pca, kmeans.labels_)}')\n\n\nSilhouette Score: 0.3276664537712163\n\n\nResults: Taking a closer look at the clusters, cluster 0 stands out with the highest dropout rate, highest percent of student who are chronically absent, and lowest college persistence rate. The cluster is also associated with several socioeconomic challenges, including the highest percentage of students elgibile for public assistance from the NYC Human Resources Administration (HRA)1, a high Economic Need Index, the lowest percentage of people with a Bachelor’s degree or higher, highest percentage of individuals with disabilities, lowest median household income, and highest percentage of households on food stamps.\nIt is evident that the K-means clustering is able to effectively find groupings of schools based on socioeconomic factors. This emphasizes that these features are significant predictors of poor high school outcomes. However, as shown by the plot and our silhouette score, there is limited separation between our clusters and some overlap exists. This suggets that our current approach may not fully capture the complexity of the data, and may need to use alternate non-linear algorithms for clustering."
  },
  {
    "objectID": "technical-details/unsupervised-learning/main.html#dbscan",
    "href": "technical-details/unsupervised-learning/main.html#dbscan",
    "title": "Unsupervised Learning",
    "section": "DBSCAN",
    "text": "DBSCAN\nDensity-Based Spatial Clustering of Applications with Noise (DBSCAN) is an unsupervised learning clustering algorithm. It is effective for identifying clusters in data with irregular, non-linear relationships. Unlike other clustering algorithms, DBSCAN can detect outliers by identifying points that do not fit well into any cluster and labels them as noise.\nThe important hyperparameters are epsilon, the maximum distance between two samples from them to be considered in the same cluster, and min points, the minimum number of points required to form a dense region. I will perform DBSCAN on the subset of data chosen during our feature engineering. First, I will apply PCA on the data to reduce dimensionality.\n\n\nCode\ndf_subset = pd.read_csv('../../data/processed-data/df_subset_regression.csv', index_col=None)\n\n\n\n\nCode\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(df_subset)\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n\n\n\nCode\ndbscan = DBSCAN(eps=0.5, min_samples=5)\nclusters = dbscan.fit_predict(X_pca)\n\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis')\nplt.xlabel(\"PCA 1\")\nplt.ylabel(\"PCA 2\")\nplt.title(\"DBSCAN Clustering after PCA\")\nplt.show()\n\nprint(f\"Silhouette Score: {silhouette_score(X_pca, clusters)}\")\n\n\n\n\n\n\n\n\n\nSilhouette Score: 0.3929752973482768\n\n\nNow we need to tune the hyperparameters to see if it can raise our silhouette score. The following function is adapted from lecture notes2\n\n\nCode\ndef maximize_silhouette(X,algo=\"ag\",nmax=20,i_plot=False):\n    X=np.ascontiguousarray(X)\n    print(X.shape)\n\n    params=[]; sil_scores=[]\n    sil_max=-10\n\n    for param in range(2,nmax+1):\n        if(algo==\"ag\"):\n            model = sklearn.cluster.AgglomerativeClustering(n_clusters=param).fit(X)\n            labels=model.labels_\n\n        if(algo==\"dbscan\"):\n            param=0.25*(param-1)\n            model = sklearn.cluster.DBSCAN(eps=param).fit(X)\n            labels=model.labels_\n\n        try:\n            sil_scores.append(sklearn.metrics.silhouette_score(X,labels))\n            params.append(param)\n        except:\n            continue\n\n        if(sil_scores[-1]&gt;sil_max):\n             opt_param=param\n             sil_max=sil_scores[-1]\n             opt_labels=labels\n\n    print(\"OPTIMAL PARAMETER =\",opt_param)\n\n    if(i_plot):\n        fig, ax = plt.subplots()\n        ax.plot(params, sil_scores, \"-o\")\n        ax.set(xlabel='Hyper-parameter', ylabel='Silhouette')\n        plt.show()\n\n    return opt_labels\n\n\n\n\nCode\nopt_labels=maximize_silhouette(X_pca,algo=\"dbscan\",nmax=15, i_plot=True)\n\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=opt_labels, cmap='viridis')\nplt.xlabel(\"PCA 1\")\nplt.ylabel(\"PCA 2\")\nplt.title(\"DBSCAN Clustering after PCA\")\nplt.show()\n\nprint(f\"Silhouette Score: {silhouette_score(X_pca, opt_labels)}\")\n\n\n(501, 2)\nOPTIMAL PARAMETER = 1.5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSilhouette Score: 0.5450321295485361\n\n\nResults: After tuning the hyperparameters, one can observe better separability among our clusters, with a silhouette score of 0.54. This performance exceeds that of the original DBSCAN and K-means clustering results. However, one limitation is that most schools are grouped into a single large cluster. Despite this, there is a smaller cluster that might be capturing schools with similar outcomes. The lone purple dot likely represents noise or an outlier."
  },
  {
    "objectID": "technical-details/unsupervised-learning/main.html#hierarchical-clustering",
    "href": "technical-details/unsupervised-learning/main.html#hierarchical-clustering",
    "title": "Unsupervised Learning",
    "section": "Hierarchical Clustering",
    "text": "Hierarchical Clustering\nHierarchical clustering is a clustering technique that builds a tree-like structure of clusters to organize our data. It does this in two ways: - Agglomerative: A bottom up approach where each observation starts as its own cluster and is merged with others as it moves up the hierarchy - Divisive: A top down approach where all data points start in one cluster, and are split recursively as you go down the hierarchy\nThe agglomerative approach is more commonly used, so I will apply this method to the PCA-reduced data. Unlike kmeans, hierarchical clustering doesn’t require us to specify a k number of clusters. It can be more flexible. We will visualize it with a dendogram to show insights into its structure.\n\n\nCode\nopt_labels=maximize_silhouette(X_pca,algo=\"ag\",nmax=15, i_plot=True)\n\nscatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=opt_labels, cmap='viridis')\nplt.xlabel(\"PCA 1\")\nplt.ylabel(\"PCA 2\")\nplt.title(\"Agglomerative Clustering after PCA\")\nplt.legend(*scatter.legend_elements(), title=\"Clusters\")\nplt.show()\n\nprint(f\"Silhouette Score: {silhouette_score(X_pca, opt_labels)}\")\n\n\n(501, 2)\nOPTIMAL PARAMETER = 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSilhouette Score: 0.5769711294126749\n\n\nNow I can add clusters back to dataframe and visualize how the target variables appear in each cluster\n\n\nCode\ndf_subset['Agglomerative_Cluster'] = opt_labels\n\ndf_subset['dropout'] = np.exp(df_subset['log_dropout_rate']) - 1\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nsns.boxplot(data=df_subset, x='Agglomerative_Cluster', y='Percent of Students Chronically Absent', ax=axes[0])\nsns.boxplot(data=df_subset, x='Agglomerative_Cluster', y='Metric Value - College Persistence', ax=axes[1])\nsns.boxplot(data=df_subset, x='Agglomerative_Cluster', y='dropout', ax=axes[2])\n\naxes[0].set_title('Chronic Absenteeism')\naxes[1].set_title('College Persistence')\naxes[2].set_title('Dropout Rate')\n\naxes[0].set_ylabel('Percentage of Students Chronically Absent')\naxes[1].set_ylabel('College Persistence')\naxes[2].set_ylabel('Dropout Rate')\n\naxes[0].set_xlabel('Agglomerative Cluster')\naxes[1].set_xlabel('Agglomerative Cluster')\naxes[2].set_xlabel('Agglomerative Cluster')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n3\n\n\nCode\nZ = linkage(X_pca, 'ward')\n\nplt.figure(figsize=(15, 7))\ndendrogram(Z, truncate_mode='level', p=10)\nplt.title('Dendrogram for Agglomerative Clustering')\nplt.xlabel('Data points')\nplt.ylabel('Distance')\nplt.show()\n\n\n\n\n\n\n\n\n\nResults: The Agglomerative Clustering algorithm achieved the highest silhouette score among the clustering methods tested. In addition, it is clear that Cluster 1 contains schools with the best student outcomes, with the lowest chronic absenteeism, lowest dropout rates, and highest college persistence. This indicates that the algorithm successfully identified meaningful patterns in the data, emphasizing the impact of these features on school outcomes. By examining the qualities and socioeconomic factors associated with the schools in this cluster, one can gain insights into the key drivers of success in these public high schools. In addition, the dendogram helps us visualize how the schools are grouped at different levels of similarity and the hierarchical relationships between them.\n\nConclusion\nI applied various clustering techniques and dimensionality reduction methods, and was able to identify key patterns in the school data. PCA revealed that three components explained most of the variance, with a relationship between dropout rates and principal components. t-SNE uncovered distinct groups of schools based on college persistence at the local level but struggled with global separation at higher perplexity values.\nK-means clustering was able to highlight schools with socioeconomic challenges but was not able to clearly separate the clusters. After tuning DBSCAN, I saw a bit better separability, but most schools were in one large cluster. Agglomerative Clustering, had the highest silhouette score, and was able to identify schools with the best outcomes, shown by the our targets like chronic absenteeism, dropout rates, and college persistence. The dendrogram also provided insight into the hierarchical relationships between schools.\nOverall, Agglomerative Clustering provided the most meaningful insights, emphasizing the ability of my features to predict school success."
  },
  {
    "objectID": "index.html#motivation",
    "href": "index.html#motivation",
    "title": "Breaking the Cycle: How School and Socioeconomics Shape High School Dropout and College Success",
    "section": "Motivation:",
    "text": "Motivation:\nDropping out of high school has often been linked to many long term negative outcomes. Research shows that students who drop out of high school are more likely to face unemployment, earn lower wages, engage in high-risk behaviors, become incarcerated, and impose significant costs on society1. Through this website, I aim to explore the factors that potentially contribute to high school dropout rates, with the goal of identifying opportunities for early intervention to mitigate these negative outcomes. Particularly, I wanted to look at how these metrics manifest in New York City public schools. My focus will be on understanding how school quality and socioeconomic factors influence student outcomes, specifically chronic absenteeism (missing more than 10% of the school year), dropout rates, and college persistence (returning to college after the first year).\nThis research is intended to inform policymakers, researchers, and data enthusiasts interested in understanding the factors that contribute to chronic absenteeism, dropout rates, and college persistence. I hypothesize that these three outcomes are interconnected. For instance, high chronic absenteeism may correlate with higher dropout rates, and even if students avoid dropping out of high school, could there still be a risk of low college persistence? These are the key questions I aim to address through this research.\n\nData Science Questions:\n\nHow does a school’s environment contribute to better student outcomes?\nWhat are the most significant predictors of student absenteeism, dropout rates and college persistence?\nWhat are the interactions between chronic absenteeism, dropout rates, and college persistence?\nHow does socioeconomic status impact student absenteeism, dropout rates and college persistence?\nHow can early academic indicators be used to identify schools at risk of high dropout or not persisting in college?\n\n\n\nRelevant Current Research\nSchool building condition, school attendance, and academic achievement in New York City public schools: A mediation model: This study, published in the Journal of Environmental Psychology in 2008, examined the relationship between school building condition and the academic achievement of students in elementary schools in Manhattan, New York City. The researchers found that school building condition was positively related to student achievement in mathematics and English Language Arts. They also found that attendance important to this relationship, suggesting that students in better-quality buildings are more likely to attend school, which in turn leads to better academic outcomes.2\nA Public Health Perspective on School Dropout and Adult Outcomes: A Prospective Study of Risk and Protective Factors from Age 5 to 27: This research paper investigates the long-term consequences of high school dropout, framing it as a significant public health issue. A study followed 585 individuals from age 5 to 27, analyzing the correlation between dropping out and negative outcomes like unemployment, arrest, and poor health, finding a strong link between them. The researchers identified several risk and protective factors, such as low socioeconomic status at age 5 and peer rejection in elementary school. The findings highlight the importance of early intervention and suggest that addressing school dropout proactively could significantly improve individual lives and reduce societal costs.1\nNeighborhood Poverty and Public Policy: A 5-Year Follow-Up of Children’s Educational Outcomes in the New York City Moving to Opportunity Demonstration: This research paper analyzes the long-term effects of the Moving to Opportunity (MTO) program, an experiment that provided housing vouchers to low-income families in high-poverty neighborhoods to relocate to lower-poverty areas. The study focuses on a subset of New York City children followed for five years, comparing their educational outcomes with those who remained in high-poverty neighborhoods. The results revealed negative effects on grades and school engagement for both boys and girls in low-poverty neighborhoods. The study highlights the necessity of improving educational outcomes for low-income minority children, focusing on family, neighborhood, housing, and school factors.3\n\n\nNext Steps\nThis website offers data driven insights, visualizations, and machine learning models to dive into this topic. I invite you to explore the content!"
  },
  {
    "objectID": "technical-details/llm-usage-log.html",
    "href": "technical-details/llm-usage-log.html",
    "title": "LLM usage log",
    "section": "",
    "text": "LLM tools were used in the following way for the tasks below"
  },
  {
    "objectID": "technical-details/llm-usage-log.html#brainstorming",
    "href": "technical-details/llm-usage-log.html#brainstorming",
    "title": "LLM usage log",
    "section": "Brainstorming",
    "text": "Brainstorming\n\nChat GPT was used to brainstorm project ideas and provide feedback and refine the project plan.\nUse Chat GPT to decide what relevant columns to get from 10,000+ columns of Census Data"
  },
  {
    "objectID": "technical-details/llm-usage-log.html#writing",
    "href": "technical-details/llm-usage-log.html#writing",
    "title": "LLM usage log",
    "section": "Writing:",
    "text": "Writing:\n\nProofreading all text\nText summarization for literature review\nUsed to convert formulas written into Latex format for readibility\nThink of a fun engaging title"
  },
  {
    "objectID": "technical-details/llm-usage-log.html#code",
    "href": "technical-details/llm-usage-log.html#code",
    "title": "LLM usage log",
    "section": "Code:",
    "text": "Code:\n\nCode commenting and explanatory documentation\nChatGPT was used to aid in generating code to navigate the American Community Survey Census API\nRun into some issues with agglomerative clustering, used Chat to debug"
  }
]